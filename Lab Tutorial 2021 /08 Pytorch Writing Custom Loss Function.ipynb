{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08 Pytorch Writing Custom Loss Function.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OA5jJjZJa_NP"
      },
      "source": [
        "# Custom Loss Function\n",
        "\n",
        "* Import\n",
        "* Cross-entropy loss function\n",
        "* MSE loss function\n",
        "* BCE loss function \n",
        "* Implementing loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HawBchZ1bBSM"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lany3DE911e"
      },
      "source": [
        "import torch\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as opt\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0glyCwGshbx3"
      },
      "source": [
        "## MSE Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIVSKwXrhbV7"
      },
      "source": [
        "# Mean square error loss function here:\n",
        "def mes_loss(y_hat, y):\n",
        "    torch.mean((y_hat - y)**2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9xUL9i9h3xB"
      },
      "source": [
        "# MSE class here\n",
        "class MyMESLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, output, label):\n",
        "        return torch.mean((output - label)**2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0jDwEiTm721",
        "outputId": "3d1ffd8e-f2f8-4b04-84f8-5ec1857dea08"
      },
      "source": [
        "output = torch.tensor([[0., 0., 0.]])\n",
        "targrt = torch.tensor([[1., 0., 0.]])\n",
        "\n",
        "# custom mse loss\n",
        "my_mse = MyMESLoss()\n",
        "loss = my_mse(output, targrt)\n",
        "print('custom mse loss:', loss.numpy())\n",
        "\n",
        "# officail mse loss \n",
        "org_mes = nn.MSELoss()\n",
        "loss = org_mes(output, targrt)\n",
        "print('officail mse loss:', loss.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "custom mse loss: 0.33333334\n",
            "officail mse loss: 0.33333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ1RRYXniTS1"
      },
      "source": [
        "## BCE Loss Function\n",
        "* Creates a criterion that measures the `Binary Cross Entropy` between the `target` and the `output`.\n",
        "\n",
        "* $ BCE = -\\frac{1}{N} \\sum_{i=0}^{N} {y_i} \\cdot log(\\widehat{y_i}) + (1-y_i) \\cdot log(1-\\widehat{y_i}) $\n",
        "\n",
        "**Reference**\n",
        "\n",
        "* BCELoss - Pytorch [Docs](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYvu_cGfi3b4"
      },
      "source": [
        "# BCE class here\n",
        "class CustomBCE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomBCE, self).__init__()\n",
        "\n",
        "    def forward(slef, outputs, labels):\n",
        "        bce_loss = labels * torch.log(outputs) + (1 - labels) * torch.log(1 - outputs)\n",
        "        total_bce_loss = torch.sum(bce_loss)\n",
        "\n",
        "        # bce loss mean 1/N\n",
        "        num_of_samples = outputs.shape[0]\n",
        "        mean_bc_loss = total_bce_loss / num_of_samples\n",
        "\n",
        "        return -mean_bc_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsazYoEDogUs",
        "outputId": "246928e6-ba8f-454f-fb3e-f2c03394c25c"
      },
      "source": [
        "# output, labels sample\n",
        "y_pred = torch.tensor([0.1580, 0.4137, 0.2285])\n",
        "y_true = torch.tensor([0.0, 1.0, 0.0]) # label (0, 1)\n",
        "\n",
        "# custom BCE loss\n",
        "loss_func = CustomBCE()\n",
        "loss = loss_func(y_pred, y_true)\n",
        "print('custom bce loss:', loss.numpy())\n",
        "\n",
        "# officail bce loss\n",
        "loss_func2 = nn.BCELoss()\n",
        "loss2 = loss_func2(y_pred, y_true)\n",
        "print('officail bce loss:', loss2.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "custom bce loss: 0.43800268\n",
            "officail bce loss: 0.4380027\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhem38bgbLzM"
      },
      "source": [
        "## Cross-Entropy Loss Function\n",
        "\n",
        "* This criterion combines `LogSoftmax` and `NLLLoss` in one single class.\n",
        "\n",
        "**Reference**\n",
        "\n",
        "* CrossEntropyLoss - Pytorch [Docs](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XT5HaRgi-_my"
      },
      "source": [
        "# CrossEntropyLoss\n",
        "class CustomCrossEntropyLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomCrossEntropyLoss, self).__init__()\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        self.nll_loss = nn.NLLLoss()\n",
        " \n",
        "    def forward(self, output, label):\n",
        "        # softmax\n",
        "        output = self.softmax(output)\n",
        "        # log(softmax_output)\n",
        "        log_output = torch.log(output)\n",
        "        nlloss_output = self.nll_loss(log_output, label)\n",
        "        return nlloss_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9ZdiO4zppWG",
        "outputId": "852648ec-5746-4078-a9aa-99e8e2c68942"
      },
      "source": [
        "# output, label sample\n",
        "\n",
        "y_pred = torch.randn(3, 3)\n",
        "y_true = torch.tensor([1, 2, 0])\n",
        "\n",
        "# officail nn.CrossEntropy\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "loss = loss_func(y_pred, y_true)\n",
        "print('officail cross-entropy loss:', loss.numpy())\n",
        "\n",
        "# custom \n",
        "loss_func2 = CustomCrossEntropyLoss()\n",
        "loss2 = loss_func2(y_pred, y_true)\n",
        "print('custom cross-entropy loss:', loss2.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "officail cross-entropy loss: 2.4982007\n",
            "custom cross-entropy loss: 2.4982007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAONXCiXdzNK"
      },
      "source": [
        "##  Implementing Loss Function\n",
        "\n",
        "* Set the device\n",
        "* Dataset & DataLoader\n",
        "* CNN Model\n",
        "* Loss function & Optimizer\n",
        "* Training Model\n",
        "* Testing Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okBg-3FVd1oM"
      },
      "source": [
        "### Set The Device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Qu7Wd7c95pR"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVvrmQC-eYwR"
      },
      "source": [
        "# hyperparameter \n",
        "train_batch_size = 100\n",
        "test_batch_szie = 1000\n",
        "learning_rate = 0.001\n",
        "num_epochs = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSL6DKQCeZtS"
      },
      "source": [
        "### Dataset & DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BwpWlGw96AD",
        "outputId": "8662d17b-ad31-4171-d523-8bb3dc96407e"
      },
      "source": [
        "train_dataset = MNIST(root = './data', train=True, download=True, transform=transforms.ToTensor())\n",
        "test_dataset= MNIST(root = './data', train=False, download=True, transform=transforms.ToTensor())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3kLLUNG97Xp"
      },
      "source": [
        "# train dataloader\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset, \n",
        "    batch_size=train_batch_size, \n",
        "    shuffle=True\n",
        "    )\n",
        "\n",
        "# test dataloader\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset, \n",
        "    batch_size=test_batch_szie, \n",
        "    shuffle=False\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljtiU6l9elcc"
      },
      "source": [
        "### CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJI_Zn6Z9-kZ"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(stride=2, kernel_size=2)\n",
        "        )\n",
        "        \n",
        "        self.dense = nn.Sequential(\n",
        "            nn.Linear(in_features=14*14*128, out_features=1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.conv_layers(x)\n",
        "        output = output.view(-1, 14*14*128)\n",
        "        output = self.dense(output)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jq83HJyM-AaI"
      },
      "source": [
        "model = CNN().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eYcuGireqK6"
      },
      "source": [
        "### Loss Function & Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_PrUy-o-B5v"
      },
      "source": [
        "# use our custom cross entropy loss\n",
        "loss_func = CustomCrossEntropyLoss()\n",
        "optimizer = opt.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ifs6ij2-e04m"
      },
      "source": [
        "### Training Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W75Sufhx-HoU",
        "outputId": "63835c4c-dbf1-42f9-bcdc-29e19a97de6d"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "    for idx, (images, labels) in enumerate(train_loader):\n",
        "        images = Variable(images.to(device))\n",
        "        labels = Variable(labels.to(device))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = loss_func(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (idx+1) % 200 == 0:\n",
        "            print(\"Epoch: %d, Batch: %d, Loss: %.4f\" %(epoch+1, idx+1, loss.data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Batch: 200, Loss: 0.1488\n",
            "Epoch: 1, Batch: 400, Loss: 0.0756\n",
            "Epoch: 1, Batch: 600, Loss: 0.0576\n",
            "Epoch: 2, Batch: 200, Loss: 0.0268\n",
            "Epoch: 2, Batch: 400, Loss: 0.0353\n",
            "Epoch: 2, Batch: 600, Loss: 0.0414\n",
            "Epoch: 3, Batch: 200, Loss: 0.0082\n",
            "Epoch: 3, Batch: 400, Loss: 0.0026\n",
            "Epoch: 3, Batch: 600, Loss: 0.0391\n",
            "Epoch: 4, Batch: 200, Loss: 0.0038\n",
            "Epoch: 4, Batch: 400, Loss: 0.0009\n",
            "Epoch: 4, Batch: 600, Loss: 0.0080\n",
            "Epoch: 5, Batch: 200, Loss: 0.0008\n",
            "Epoch: 5, Batch: 400, Loss: 0.0326\n",
            "Epoch: 5, Batch: 600, Loss: 0.0028\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcAdcJgNe3VJ"
      },
      "source": [
        "### Testing Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7rauK19-MVS",
        "outputId": "3a879a55-5959-44a2-ee1f-1080302730e1"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "for images, labels in test_loader:\n",
        "  images = Variable(images.to(device))\n",
        "  outputs = model(images)\n",
        "\n",
        "  _, pred = torch.max(outputs.data, 1)\n",
        "  \n",
        "  correct += (pred == labels.to(device)).sum()\n",
        "  total += labels.size(0)\n",
        "\n",
        "print('Accuracy:%.3f%%' %(100.0 * float(correct)/float(total)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:98.970%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}