{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OA5jJjZJa_NP"
      },
      "source": [
        "# Custom Loss Function\n",
        "\n",
        "* Import\n",
        "* Cross-entropy loss function\n",
        "* MSE loss function\n",
        "* BCE loss function \n",
        "* Implementing loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HawBchZ1bBSM"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lany3DE911e"
      },
      "source": [
        "import torch\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as opt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0glyCwGshbx3"
      },
      "source": [
        "## MSE Loss Function\n",
        "\n",
        "$MSE=\\frac{1}{n}\\sum_{i=1}^{n}({y_i}-\\widehat{y_i})^2$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIVSKwXrhbV7"
      },
      "source": [
        "# Mean square error loss function here:\n",
        "def mes_loss(y_hat, y):\n",
        "    torch.mean((y - y_hat)**2)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9xUL9i9h3xB"
      },
      "source": [
        "# MSE class\n",
        "class MyMESLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyMESLoss, self).__init__()\n",
        "\n",
        "    def forward(self, output, label):\n",
        "        return torch.mean((label - output)**2)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0jDwEiTm721",
        "outputId": "c388bbd9-e324-400b-a01a-5ab188940851"
      },
      "source": [
        "output = torch.tensor([[0., 0., 0.]])\n",
        "targrt = torch.tensor([[3., 0., 0.]])\n",
        "\n",
        "# custom mse loss\n",
        "my_mse = MyMESLoss()\n",
        "loss = my_mse(output, targrt)\n",
        "print('my mse loss:', loss.numpy())\n",
        "\n",
        "# officail mse loss \n",
        "org_mes = nn.MSELoss()\n",
        "loss = org_mes(output, targrt)\n",
        "print('officail mse loss:', loss.numpy())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my mse loss: 3.0\n",
            "officail mse loss: 3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ1RRYXniTS1"
      },
      "source": [
        "## BCE Loss Function\n",
        "* Creates a criterion that measures the `Binary Cross Entropy` between the `target` and the `output`.\n",
        "\n",
        "* $ BCE = -\\frac{1}{N} \\sum_{i=0}^{N} ({y_i} \\cdot log(\\widehat{y_i}) + (1-y_i) \\cdot log(1-\\widehat{y_i}))$\n",
        "\n",
        "**Reference**\n",
        "\n",
        "* BCELoss - Pytorch [Docs](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYvu_cGfi3b4"
      },
      "source": [
        "# BCE class here\n",
        "class MyBCE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyBCE, self).__init__()\n",
        "\n",
        "    def forward(slef, outputs, labels):\n",
        "        bce_loss = labels * torch.log(outputs) + (1 - labels) * torch.log(1 - outputs)\n",
        "        total_bce_loss = torch.sum(bce_loss)\n",
        "\n",
        "        # bce loss mean 1/N\n",
        "        num_of_samples = outputs.shape[0]\n",
        "        mean_bc_loss = total_bce_loss / num_of_samples\n",
        "\n",
        "        return -mean_bc_loss"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsazYoEDogUs",
        "outputId": "9780d4f2-7772-447f-849f-b7264f00356d"
      },
      "source": [
        "# output, labels sample\n",
        "y_pred = torch.tensor([0.1580, 0.4137, 0.2285])\n",
        "y_true = torch.tensor([0.0, 1.0, 0.0]) # label (0, 1)\n",
        "\n",
        "# custom BCE loss\n",
        "loss_func = MyBCE()\n",
        "loss = loss_func(y_pred, y_true)\n",
        "print('my bce loss:', loss.numpy())\n",
        "\n",
        "# officail bce loss\n",
        "loss_func2 = nn.BCELoss()\n",
        "loss2 = loss_func2(y_pred, y_true)\n",
        "print('officail bce loss:', loss2.numpy())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my bce loss: 0.43800268\n",
            "officail bce loss: 0.4380027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhem38bgbLzM"
      },
      "source": [
        "## Cross-Entropy Loss Function\n",
        "\n",
        "* This criterion combines `LogSoftmax` and `NLLLoss` in one single class.\n",
        "\n",
        "**Reference**\n",
        "\n",
        "* CrossEntropyLoss - Pytorch [Docs](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XT5HaRgi-_my"
      },
      "source": [
        "# CrossEntropyLoss\n",
        "class MyCrossEntropyLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyCrossEntropyLoss, self).__init__()\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        self.nll_loss = nn.NLLLoss()\n",
        " \n",
        "    def forward(self, output, label):\n",
        "        # softmax\n",
        "        output = self.softmax(output)\n",
        "        # log(softmax_output)\n",
        "        log_output = torch.log(output)\n",
        "        nlloss_output = self.nll_loss(log_output, label)\n",
        "        return nlloss_output"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# exmaple 0-2: 3 classes\n",
        "y_true = torch.tensor([1, 2, 2, 0])\n",
        "\n",
        "# random y_pred\n",
        "N = y_true.shape[0]\n",
        "y_pred = torch.randn(N, 3)\n",
        "\n",
        "print(y_pred)\n",
        "print('')\n",
        "print('pred labels', torch.argmax(y_pred, 1))\n",
        "print('true labels', y_true)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EjK-RbUVuQg",
        "outputId": "b5932b3c-540c-4aba-e5d3-c9732ab293f3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.0356,  0.4524, -1.5878],\n",
            "        [ 0.6704, -0.6612,  0.2688],\n",
            "        [-1.4597,  1.4313,  0.0816],\n",
            "        [ 0.1927, -0.9157, -2.2712]])\n",
            "\n",
            "pred labels tensor([0, 0, 1, 0])\n",
            "true labels tensor([1, 2, 2, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9ZdiO4zppWG",
        "outputId": "8c8d7045-64ec-4bc3-8a31-204d76d30b19"
      },
      "source": [
        "# officail nn.CrossEntropy\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "loss = loss_func(y_pred, y_true)\n",
        "print('Officail cross-entropy loss:', loss.numpy())\n",
        "\n",
        "# custom \n",
        "loss_func2 = MyCrossEntropyLoss()\n",
        "loss2 = loss_func2(y_pred, y_true)\n",
        "print('My cross-entropy loss:', loss2.numpy())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Officail cross-entropy loss: 1.0259023\n",
            "My cross-entropy loss: 1.0259023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAONXCiXdzNK"
      },
      "source": [
        "##  Implementing Loss Function\n",
        "\n",
        "* Set the device\n",
        "* Dataset & DataLoader\n",
        "* CNN Model\n",
        "* Loss function & Optimizer\n",
        "* Training Model\n",
        "* Testing Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okBg-3FVd1oM"
      },
      "source": [
        "### Set The Device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Qu7Wd7c95pR"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVvrmQC-eYwR"
      },
      "source": [
        "# hyperparameter \n",
        "train_batch_size = 100\n",
        "test_batch_szie = 1000\n",
        "learning_rate = 0.001\n",
        "num_epochs = 5"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSL6DKQCeZtS"
      },
      "source": [
        "### Dataset & DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BwpWlGw96AD"
      },
      "source": [
        "train_dataset = MNIST(root = './data', train=True, download=True, transform=transforms.ToTensor())\n",
        "test_dataset= MNIST(root = './data', train=False, download=True, transform=transforms.ToTensor())"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3kLLUNG97Xp"
      },
      "source": [
        "# train dataloader\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset, \n",
        "    batch_size=train_batch_size, \n",
        "    shuffle=True\n",
        "    )\n",
        "\n",
        "# test dataloader\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset, \n",
        "    batch_size=test_batch_szie, \n",
        "    shuffle=False\n",
        "    )"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljtiU6l9elcc"
      },
      "source": [
        "### CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJI_Zn6Z9-kZ"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(stride=2, kernel_size=2)\n",
        "        )\n",
        "        \n",
        "        self.dense = nn.Sequential(\n",
        "            nn.Linear(in_features=14*14*128, out_features=1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.conv_layers(x)\n",
        "        output = output.view(-1, 14*14*128)\n",
        "        output = self.dense(output)\n",
        "        return output"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jq83HJyM-AaI"
      },
      "source": [
        "model = CNN().to(device)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eYcuGireqK6"
      },
      "source": [
        "### Loss Function & Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_PrUy-o-B5v"
      },
      "source": [
        "# use our custom cross entropy loss\n",
        "loss_func = MyCrossEntropyLoss()\n",
        "optimizer = opt.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ifs6ij2-e04m"
      },
      "source": [
        "### Training Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W75Sufhx-HoU",
        "outputId": "a12a863d-e3f4-419d-a0a0-c4ea6dd7f978"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "    for idx, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = loss_func(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (idx+1) % 200 == 0:\n",
        "            print(\"Epoch: %d, Batch: %d, Loss: %.4f\" %(epoch+1, idx+1, loss.data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Batch: 200, Loss: 0.1242\n",
            "Epoch: 1, Batch: 400, Loss: 0.0261\n",
            "Epoch: 1, Batch: 600, Loss: 0.0606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcAdcJgNe3VJ"
      },
      "source": [
        "### Testing Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7rauK19-MVS"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "for images, labels in test_loader:\n",
        "  images = images.to(device)\n",
        "  outputs = model(images)\n",
        "\n",
        "  _, pred = torch.max(outputs.data, 1)\n",
        "  \n",
        "  correct += (pred == labels.to(device)).sum()\n",
        "  total += labels.size(0)\n",
        "\n",
        "print('Accuracy:%.3f%%' %(100.0 * float(correct)/float(total)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}