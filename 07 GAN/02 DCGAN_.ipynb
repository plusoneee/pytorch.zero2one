{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dl_ch7_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQ4jGmiSlIfb"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K_7VRoWla6g"
      },
      "source": [
        "def to_variable(x):\n",
        "  if torch.cuda.is_available():\n",
        "    x = x.cuda()\n",
        "  return Variable(x)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihxWIF5OlcC8"
      },
      "source": [
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize(mean=0.5, std=0.5)\n",
        "])"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfrxXIb5ldHt"
      },
      "source": [
        "from torchvision.datasets import MNIST\n",
        "train_dataset = MNIST(root = './', train=True, download=True, transform=transform)\n",
        "test_dataset= MNIST(root = './', train=False, download=True, transform=transform)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqAIlfy0leZm"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.utils.data as Data\n",
        "data_loader = Data.DataLoader(dataset=train_dataset, \n",
        "                               batch_size=100, \n",
        "                               shuffle=True)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGdBLOPvlf5s"
      },
      "source": [
        "class DisCriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(DisCriminator , self).__init__()\n",
        "    self.conv1 = nn.Conv2d(\n",
        "        in_channels = 1,\n",
        "        out_channels = 64,\n",
        "        kernel_size = 5,\n",
        "        stride = 2,\n",
        "        padding = 2,\n",
        "        bias = True)\n",
        "    self.leaky_relu = nn.LeakyReLU()\n",
        "    self.dropout_2d = nn.Dropout2d(0.3)\n",
        "    self.conv2 = nn.Conv2d(\n",
        "        in_channels = 64,\n",
        "        out_channels = 128,\n",
        "        kernel_size = 5,\n",
        "        stride = 2,\n",
        "        padding = 2,\n",
        "        bias = True)\n",
        "    self.linearl = nn.Linear(128*7*7 , 1 , bias = True)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "  def forward(self , x):\n",
        "    out = self.conv1(x)\n",
        "    out = self.leaky_relu(out)\n",
        "    out = self.dropout_2d(out)\n",
        "    out = self.conv2(out)\n",
        "    out = self.leaky_relu(out)\n",
        "    out = self.dropout_2d(out)\n",
        "    out = out.view(-1 , 128*7*7)\n",
        "    out = self.linearl(out)\n",
        "    out = self.sigmoid(out)\n",
        "    return out"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_L5Dm7iljf1"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self , latent_dim = 100 , batchnorm = True):\n",
        "    super(Generator , self).__init__()\n",
        "    self.latent_dim = latent_dim\n",
        "    self.batchnorm = batchnorm\n",
        "    self.linearl = nn.Linear(latent_dim , 7*7*256 , bias=False)\n",
        "    self.bn1d1 = nn.BatchNorm1d(256*7*7) if batchnorm else None\n",
        "    self.leaky_relu = nn.LeakyReLU()\n",
        "    self.conv1 = nn.Conv2d(\n",
        "        in_channels = 256,\n",
        "        out_channels = 128,\n",
        "        kernel_size = 5,\n",
        "        stride = 1,\n",
        "        padding = 2,\n",
        "        bias = False\n",
        "    )\n",
        "    self.bn2d1 = nn.BatchNorm2d(128) if batchnorm else None\n",
        "    self.conv2 = nn.ConvTranspose2d(\n",
        "        in_channels = 128,\n",
        "        out_channels = 64,\n",
        "        kernel_size = 4,\n",
        "        stride = 2,\n",
        "        padding = 1,\n",
        "        bias = False\n",
        "    )\n",
        "    self.bn2d2 = nn.BatchNorm2d(64) if batchnorm else None\n",
        "    self.conv3 = nn.ConvTranspose2d(\n",
        "        in_channels = 64,\n",
        "        out_channels = 1,\n",
        "        kernel_size = 4,\n",
        "        stride = 2,\n",
        "        padding = 1,\n",
        "        bias = False\n",
        "    )\n",
        "    self.tanh = nn.Tanh()\n",
        "  def forward(self , x):\n",
        "    out = self.linearl(x)\n",
        "    if self.batchnorm:\n",
        "      out = self.bn1d1(out)\n",
        "    out = self.leaky_relu(out)\n",
        "    out = out.view((-1 , 256 ,7 ,7))\n",
        "    out = self.conv1(out)\n",
        "    if self.batchnorm:\n",
        "      out = self.bn2d1(out)\n",
        "    out = self.leaky_relu(out)  \n",
        "    out = self.conv2(out)\n",
        "    if self.batchnorm:\n",
        "      out = self.bn2d2(out)\n",
        "    out = self.leaky_relu(out)\n",
        "    out = self.conv3(out)\n",
        "    out = self.tanh(out)\n",
        "    return out"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peR8Xafh4gCq"
      },
      "source": [
        "DCG = Generator()\n",
        "DCD = DisCriminator()"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzxsV6p05vCq"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  DCD.cuda()\n",
        "  DCG.cuda()"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJVaTedZ8IgY"
      },
      "source": [
        "from torchvision.utils import save_image"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "847hzset-kVy"
      },
      "source": [
        "def denorm(x):\n",
        "  out  = (x+1) / 2\n",
        "  return out.clamp(0,1) "
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4FQ9pYr6KIc"
      },
      "source": [
        "loss_func = nn.BCELoss()\n",
        "dcd_opt = torch.optim.Adam(DCD.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
        "dcg_opt = torch.optim.Adam(DCG.parameters(), lr=0.001, betas=(0.5, 0.999))"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUrBEDUG6uRU",
        "outputId": "d1411d75-2880-4492-c7a0-cbc58af4ba7b"
      },
      "source": [
        "for epoch in range(50):\n",
        "  for i, (images, _) in enumerate(data_loader):\n",
        "    batch_size = images.size(0)\n",
        "    images = to_variable(images)\n",
        "\n",
        "    real_labels = to_variable(torch.ones(batch_size,1))\n",
        "    fake_labels = to_variable(torch.zeros(batch_size,1))\n",
        "\n",
        "    outputs = DCD(images)\n",
        "    d_loss_real = loss_func(outputs , real_labels)\n",
        "    real_score = outputs\n",
        "\n",
        "    z = to_variable(torch.randn(batch_size , 100))\n",
        "    fake_images = DCG(z)\n",
        "    outputs = DCD(fake_images)\n",
        "    d_loss_fake = loss_func(outputs , fake_labels)\n",
        "    fake_score = outputs\n",
        "\n",
        "    d_loss = d_loss_real+d_loss_fake\n",
        "    DCD.zero_grad()\n",
        "    d_loss.backward()\n",
        "    dcd_opt.step() \n",
        "\n",
        "    z = to_variable(torch.randn(batch_size , 100))\n",
        "    fake_images = DCG(z)\n",
        "    outputs = DCD(fake_images)\n",
        "\n",
        "    g_loss = loss_func(outputs , real_labels)\n",
        "    DCD.zero_grad()\n",
        "    DCG.zero_grad()\n",
        "    g_loss.backward()\n",
        "    dcg_opt.step()\n",
        "\n",
        "    if (i+1)%300 == 0:\n",
        "      print(\"Epoch %d, batch %d, d_loss: %.4f , g_loss: %.4f,\"\n",
        "      \" D(x): %.2f , D(G(z)): %.2f\"\n",
        "      %(epoch, i+1 , d_loss.data , g_loss.data , \n",
        "        real_score.data.mean() , fake_score.data.mean()))\n",
        "  if epoch == 0:\n",
        "    images = images.view(images.size(0) , 1 , 28 , 28)\n",
        "    save_image(denorm(images) , \"./data1/real_images.png\")\n",
        "  fake_images = fake_images.view(fake_images.size(0) , 1 , 28 , 28)\n",
        "  save_image(denorm(fake_images), \"./data1/fake_images-%d.png\"%(epoch+1))\n"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, batch 300, d_loss: 1.2461 , g_loss: 0.8178, D(x): 0.58 , D(G(z)): 0.47\n",
            "Epoch 0, batch 600, d_loss: 1.2770 , g_loss: 0.9189, D(x): 0.56 , D(G(z)): 0.47\n",
            "Epoch 1, batch 300, d_loss: 1.3925 , g_loss: 0.9700, D(x): 0.49 , D(G(z)): 0.46\n",
            "Epoch 1, batch 600, d_loss: 1.3569 , g_loss: 0.9516, D(x): 0.55 , D(G(z)): 0.49\n",
            "Epoch 2, batch 300, d_loss: 1.2084 , g_loss: 0.7795, D(x): 0.54 , D(G(z)): 0.41\n",
            "Epoch 2, batch 600, d_loss: 1.2238 , g_loss: 0.9888, D(x): 0.58 , D(G(z)): 0.46\n",
            "Epoch 3, batch 300, d_loss: 1.2902 , g_loss: 0.9517, D(x): 0.56 , D(G(z)): 0.47\n",
            "Epoch 3, batch 600, d_loss: 1.3198 , g_loss: 0.9802, D(x): 0.51 , D(G(z)): 0.43\n",
            "Epoch 4, batch 300, d_loss: 1.3147 , g_loss: 0.9847, D(x): 0.54 , D(G(z)): 0.44\n",
            "Epoch 4, batch 600, d_loss: 1.2468 , g_loss: 0.8836, D(x): 0.57 , D(G(z)): 0.46\n",
            "Epoch 5, batch 300, d_loss: 1.2195 , g_loss: 0.8719, D(x): 0.53 , D(G(z)): 0.39\n",
            "Epoch 5, batch 600, d_loss: 1.1018 , g_loss: 1.0026, D(x): 0.60 , D(G(z)): 0.41\n",
            "Epoch 6, batch 300, d_loss: 1.1668 , g_loss: 0.9645, D(x): 0.56 , D(G(z)): 0.39\n",
            "Epoch 6, batch 600, d_loss: 1.2074 , g_loss: 1.0161, D(x): 0.63 , D(G(z)): 0.46\n",
            "Epoch 7, batch 300, d_loss: 1.2529 , g_loss: 0.9794, D(x): 0.51 , D(G(z)): 0.39\n",
            "Epoch 7, batch 600, d_loss: 1.2433 , g_loss: 0.9108, D(x): 0.56 , D(G(z)): 0.43\n",
            "Epoch 8, batch 300, d_loss: 1.2200 , g_loss: 0.9542, D(x): 0.55 , D(G(z)): 0.39\n",
            "Epoch 8, batch 600, d_loss: 1.2136 , g_loss: 0.9607, D(x): 0.55 , D(G(z)): 0.41\n",
            "Epoch 9, batch 300, d_loss: 1.1818 , g_loss: 0.8895, D(x): 0.65 , D(G(z)): 0.46\n",
            "Epoch 9, batch 600, d_loss: 1.2175 , g_loss: 1.0496, D(x): 0.53 , D(G(z)): 0.37\n",
            "Epoch 10, batch 300, d_loss: 1.1990 , g_loss: 0.9183, D(x): 0.55 , D(G(z)): 0.39\n",
            "Epoch 10, batch 600, d_loss: 1.1350 , g_loss: 1.0706, D(x): 0.61 , D(G(z)): 0.41\n",
            "Epoch 11, batch 300, d_loss: 1.3272 , g_loss: 0.8045, D(x): 0.49 , D(G(z)): 0.38\n",
            "Epoch 11, batch 600, d_loss: 1.2042 , g_loss: 1.0958, D(x): 0.62 , D(G(z)): 0.45\n",
            "Epoch 12, batch 300, d_loss: 1.2262 , g_loss: 1.1246, D(x): 0.59 , D(G(z)): 0.42\n",
            "Epoch 12, batch 600, d_loss: 1.1069 , g_loss: 1.0933, D(x): 0.60 , D(G(z)): 0.38\n",
            "Epoch 13, batch 300, d_loss: 1.1177 , g_loss: 1.0368, D(x): 0.60 , D(G(z)): 0.38\n",
            "Epoch 13, batch 600, d_loss: 1.0531 , g_loss: 1.2262, D(x): 0.62 , D(G(z)): 0.36\n",
            "Epoch 14, batch 300, d_loss: 1.2809 , g_loss: 0.9759, D(x): 0.51 , D(G(z)): 0.35\n",
            "Epoch 14, batch 600, d_loss: 1.0983 , g_loss: 1.1218, D(x): 0.60 , D(G(z)): 0.34\n",
            "Epoch 15, batch 300, d_loss: 1.0460 , g_loss: 1.1148, D(x): 0.64 , D(G(z)): 0.38\n",
            "Epoch 15, batch 600, d_loss: 1.0474 , g_loss: 1.2656, D(x): 0.64 , D(G(z)): 0.38\n",
            "Epoch 16, batch 300, d_loss: 0.9951 , g_loss: 1.2854, D(x): 0.66 , D(G(z)): 0.37\n",
            "Epoch 16, batch 600, d_loss: 1.0674 , g_loss: 1.0625, D(x): 0.55 , D(G(z)): 0.29\n",
            "Epoch 17, batch 300, d_loss: 1.1190 , g_loss: 1.4447, D(x): 0.67 , D(G(z)): 0.43\n",
            "Epoch 17, batch 600, d_loss: 1.0469 , g_loss: 1.0391, D(x): 0.59 , D(G(z)): 0.31\n",
            "Epoch 18, batch 300, d_loss: 1.1181 , g_loss: 1.0264, D(x): 0.59 , D(G(z)): 0.36\n",
            "Epoch 18, batch 600, d_loss: 1.0217 , g_loss: 1.0701, D(x): 0.65 , D(G(z)): 0.36\n",
            "Epoch 19, batch 300, d_loss: 1.1325 , g_loss: 1.1297, D(x): 0.57 , D(G(z)): 0.34\n",
            "Epoch 19, batch 600, d_loss: 1.0593 , g_loss: 1.0263, D(x): 0.63 , D(G(z)): 0.36\n",
            "Epoch 20, batch 300, d_loss: 1.0676 , g_loss: 1.1273, D(x): 0.57 , D(G(z)): 0.29\n",
            "Epoch 20, batch 600, d_loss: 0.9638 , g_loss: 1.1028, D(x): 0.62 , D(G(z)): 0.30\n",
            "Epoch 21, batch 300, d_loss: 1.0300 , g_loss: 0.9976, D(x): 0.66 , D(G(z)): 0.38\n",
            "Epoch 21, batch 600, d_loss: 1.0052 , g_loss: 1.0690, D(x): 0.60 , D(G(z)): 0.30\n",
            "Epoch 22, batch 300, d_loss: 1.0861 , g_loss: 0.9863, D(x): 0.59 , D(G(z)): 0.34\n",
            "Epoch 22, batch 600, d_loss: 1.1387 , g_loss: 1.1574, D(x): 0.60 , D(G(z)): 0.36\n",
            "Epoch 23, batch 300, d_loss: 0.9956 , g_loss: 1.2334, D(x): 0.65 , D(G(z)): 0.34\n",
            "Epoch 23, batch 600, d_loss: 1.0297 , g_loss: 1.1838, D(x): 0.64 , D(G(z)): 0.35\n",
            "Epoch 24, batch 300, d_loss: 1.0292 , g_loss: 1.3914, D(x): 0.61 , D(G(z)): 0.31\n",
            "Epoch 24, batch 600, d_loss: 0.9897 , g_loss: 1.3881, D(x): 0.66 , D(G(z)): 0.34\n",
            "Epoch 25, batch 300, d_loss: 1.0130 , g_loss: 1.1863, D(x): 0.59 , D(G(z)): 0.28\n",
            "Epoch 25, batch 600, d_loss: 1.0633 , g_loss: 1.1101, D(x): 0.66 , D(G(z)): 0.38\n",
            "Epoch 26, batch 300, d_loss: 1.0088 , g_loss: 1.3630, D(x): 0.68 , D(G(z)): 0.36\n",
            "Epoch 26, batch 600, d_loss: 1.1926 , g_loss: 1.2698, D(x): 0.60 , D(G(z)): 0.40\n",
            "Epoch 27, batch 300, d_loss: 1.2356 , g_loss: 1.2221, D(x): 0.62 , D(G(z)): 0.43\n",
            "Epoch 27, batch 600, d_loss: 0.9871 , g_loss: 1.0893, D(x): 0.63 , D(G(z)): 0.31\n",
            "Epoch 28, batch 300, d_loss: 0.9448 , g_loss: 1.3727, D(x): 0.68 , D(G(z)): 0.32\n",
            "Epoch 28, batch 600, d_loss: 1.0269 , g_loss: 0.9412, D(x): 0.61 , D(G(z)): 0.32\n",
            "Epoch 29, batch 300, d_loss: 0.9948 , g_loss: 1.1776, D(x): 0.61 , D(G(z)): 0.29\n",
            "Epoch 29, batch 600, d_loss: 1.0312 , g_loss: 1.2826, D(x): 0.64 , D(G(z)): 0.33\n",
            "Epoch 30, batch 300, d_loss: 1.0619 , g_loss: 1.2069, D(x): 0.65 , D(G(z)): 0.38\n",
            "Epoch 30, batch 600, d_loss: 1.0069 , g_loss: 1.3087, D(x): 0.64 , D(G(z)): 0.32\n",
            "Epoch 31, batch 300, d_loss: 1.1095 , g_loss: 1.1640, D(x): 0.71 , D(G(z)): 0.42\n",
            "Epoch 31, batch 600, d_loss: 1.1903 , g_loss: 1.2144, D(x): 0.57 , D(G(z)): 0.33\n",
            "Epoch 32, batch 300, d_loss: 0.9947 , g_loss: 1.2224, D(x): 0.62 , D(G(z)): 0.30\n",
            "Epoch 32, batch 600, d_loss: 1.0591 , g_loss: 1.2321, D(x): 0.61 , D(G(z)): 0.33\n",
            "Epoch 33, batch 300, d_loss: 0.9510 , g_loss: 1.0214, D(x): 0.68 , D(G(z)): 0.36\n",
            "Epoch 33, batch 600, d_loss: 1.0312 , g_loss: 1.3263, D(x): 0.66 , D(G(z)): 0.35\n",
            "Epoch 34, batch 300, d_loss: 1.0103 , g_loss: 1.3835, D(x): 0.67 , D(G(z)): 0.35\n",
            "Epoch 34, batch 600, d_loss: 1.0451 , g_loss: 1.2230, D(x): 0.62 , D(G(z)): 0.31\n",
            "Epoch 35, batch 300, d_loss: 1.1377 , g_loss: 1.1707, D(x): 0.61 , D(G(z)): 0.34\n",
            "Epoch 35, batch 600, d_loss: 1.0698 , g_loss: 1.2879, D(x): 0.67 , D(G(z)): 0.38\n",
            "Epoch 36, batch 300, d_loss: 1.0787 , g_loss: 1.3333, D(x): 0.62 , D(G(z)): 0.34\n",
            "Epoch 36, batch 600, d_loss: 1.0557 , g_loss: 1.1942, D(x): 0.57 , D(G(z)): 0.30\n",
            "Epoch 37, batch 300, d_loss: 0.9404 , g_loss: 1.2191, D(x): 0.70 , D(G(z)): 0.36\n",
            "Epoch 37, batch 600, d_loss: 0.9238 , g_loss: 0.9771, D(x): 0.69 , D(G(z)): 0.32\n",
            "Epoch 38, batch 300, d_loss: 1.0436 , g_loss: 1.1340, D(x): 0.63 , D(G(z)): 0.33\n",
            "Epoch 38, batch 600, d_loss: 1.0469 , g_loss: 1.3693, D(x): 0.71 , D(G(z)): 0.42\n",
            "Epoch 39, batch 300, d_loss: 0.9949 , g_loss: 1.3420, D(x): 0.65 , D(G(z)): 0.33\n",
            "Epoch 39, batch 600, d_loss: 0.9991 , g_loss: 1.2387, D(x): 0.65 , D(G(z)): 0.33\n",
            "Epoch 40, batch 300, d_loss: 1.0917 , g_loss: 1.1032, D(x): 0.65 , D(G(z)): 0.38\n",
            "Epoch 40, batch 600, d_loss: 0.9994 , g_loss: 1.2017, D(x): 0.65 , D(G(z)): 0.33\n",
            "Epoch 41, batch 300, d_loss: 1.0252 , g_loss: 1.4671, D(x): 0.65 , D(G(z)): 0.35\n",
            "Epoch 41, batch 600, d_loss: 1.1097 , g_loss: 0.9598, D(x): 0.64 , D(G(z)): 0.37\n",
            "Epoch 42, batch 300, d_loss: 1.0753 , g_loss: 1.1797, D(x): 0.63 , D(G(z)): 0.34\n",
            "Epoch 42, batch 600, d_loss: 1.0537 , g_loss: 1.0953, D(x): 0.61 , D(G(z)): 0.32\n",
            "Epoch 43, batch 300, d_loss: 1.0753 , g_loss: 1.2606, D(x): 0.67 , D(G(z)): 0.39\n",
            "Epoch 43, batch 600, d_loss: 1.0577 , g_loss: 1.2123, D(x): 0.65 , D(G(z)): 0.35\n",
            "Epoch 44, batch 300, d_loss: 1.0357 , g_loss: 1.2544, D(x): 0.63 , D(G(z)): 0.32\n",
            "Epoch 44, batch 600, d_loss: 1.3340 , g_loss: 1.2449, D(x): 0.66 , D(G(z)): 0.47\n",
            "Epoch 45, batch 300, d_loss: 1.0297 , g_loss: 1.3000, D(x): 0.67 , D(G(z)): 0.37\n",
            "Epoch 45, batch 600, d_loss: 1.1136 , g_loss: 1.4994, D(x): 0.69 , D(G(z)): 0.43\n",
            "Epoch 46, batch 300, d_loss: 0.9997 , g_loss: 1.2991, D(x): 0.64 , D(G(z)): 0.31\n",
            "Epoch 46, batch 600, d_loss: 1.0888 , g_loss: 1.1007, D(x): 0.70 , D(G(z)): 0.43\n",
            "Epoch 47, batch 300, d_loss: 1.0561 , g_loss: 1.3255, D(x): 0.73 , D(G(z)): 0.43\n",
            "Epoch 47, batch 600, d_loss: 1.1612 , g_loss: 1.2398, D(x): 0.62 , D(G(z)): 0.39\n",
            "Epoch 48, batch 300, d_loss: 0.9849 , g_loss: 1.2579, D(x): 0.67 , D(G(z)): 0.35\n",
            "Epoch 48, batch 600, d_loss: 1.0425 , g_loss: 1.1772, D(x): 0.66 , D(G(z)): 0.36\n",
            "Epoch 49, batch 300, d_loss: 1.0277 , g_loss: 1.4609, D(x): 0.63 , D(G(z)): 0.34\n",
            "Epoch 49, batch 600, d_loss: 1.2809 , g_loss: 1.0903, D(x): 0.62 , D(G(z)): 0.42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jATyWbop8HOo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29YwaRrL74Fm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}