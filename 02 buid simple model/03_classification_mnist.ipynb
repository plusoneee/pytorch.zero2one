{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader as DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as opt\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dsets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = dsets.MNIST(root='./data', train=False, transform=transforms.ToTensor(), download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.data.shape # 60000 count, 28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOsUlEQVR4nO3dfayUdXrG8esqahrxBakpElbLYgxGjWUbxMaQVWNYX+JGjxqzpCY0Gtk/JHGThtTQP1bTYk19aZZqNrBRF5ot6yZqRHfjS0VlWxPiEVERF3WNZiFHqEEU8IUCd/84gz2rZ35zmHlmnvHc308yOTPPPc/MnSdcPO/zc0QIwPj3J3U3AKA3CDuQBGEHkiDsQBKEHUiCsANJEHYgCcKOUdl+3vbntvc0Hlvq7gmdIewoWRQRxzQeM+tuBp0h7EAShB0l/2z7Q9v/bfuCuptBZ8y18RiN7XMlbZa0T9IPJN0raVZE/L7WxtA2wo4xsf2kpF9HxL/V3Qvaw2Y8xiokue4m0D7Cjq+xPcn2xbb/1PYRtv9G0nclPVl3b2jfEXU3gL50pKR/knS6pAOSfifpyoh4q9au0BH22YEk2IwHkiDsQBKEHUiCsANJ9PRovG2OBgJdFhGjXg/R0Zrd9iW2t9h+x/YtnXwWgO5q+9Sb7QmS3pI0T9JWSS9Jmh8RmwvzsGYHuqwba/Y5kt6JiHcjYp+kX0q6ooPPA9BFnYR9mqQ/jHi9tTHtj9heaHvQ9mAH3wWgQ10/QBcRKyStkNiMB+rUyZp9m6STR7z+VmMagD7USdhfknSa7W/bPkrDP3Cwppq2AFSt7c34iNhve5GkpyRNkPRARLxRWWcAKtXTu97YZwe6rysX1QD45iDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgibaHbMY3w4QJE4r1448/vqvfv2jRoqa1o48+ujjvzJkzi/WbbrqpWL/rrrua1ubPn1+c9/PPPy/W77jjjmL9tttuK9br0FHYbb8nabekA5L2R8TsKpoCUL0q1uwXRsSHFXwOgC5inx1IotOwh6Snbb9se+Fob7C90Pag7cEOvwtABzrdjJ8bEdts/7mkZ2z/LiLWjXxDRKyQtEKSbEeH3wegTR2t2SNiW+PvDkmPSppTRVMAqtd22G1PtH3soeeSvidpU1WNAahWJ5vxUyQ9avvQ5/xHRDxZSVfjzCmnnFKsH3XUUcX6eeedV6zPnTu3aW3SpEnFea+++upivU5bt24t1pctW1asDwwMNK3t3r27OO+rr75arL/wwgvFej9qO+wR8a6kv6ywFwBdxKk3IAnCDiRB2IEkCDuQBGEHknBE7y5qG69X0M2aNatYX7t2bbHe7dtM+9XBgweL9euvv75Y37NnT9vfPTQ0VKx/9NFHxfqWLVva/u5uiwiPNp01O5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwXn2CkyePLlYX79+fbE+Y8aMKtupVKved+3aVaxfeOGFTWv79u0rzpv1+oNOcZ4dSI6wA0kQdiAJwg4kQdiBJAg7kARhB5JgyOYK7Ny5s1hfvHhxsX755ZcX66+88kqx3uonlUs2btxYrM+bN69Y37t3b7F+5plnNq3dfPPNxXlRLdbsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE97P3geOOO65YbzW88PLly5vWbrjhhuK81113XbG+evXqYh39p+372W0/YHuH7U0jpk22/Yzttxt/T6iyWQDVG8tm/M8lXfKVabdIejYiTpP0bOM1gD7WMuwRsU7SV68HvULSysbzlZKurLYtAFVr99r4KRFxaLCsDyRNafZG2wslLWzzewBUpOMbYSIiSgfeImKFpBUSB+iAOrV76m277amS1Pi7o7qWAHRDu2FfI2lB4/kCSY9V0w6Abmm5GW97taQLJJ1oe6ukH0u6Q9KvbN8g6X1J13azyfHuk08+6Wj+jz/+uO15b7zxxmL9oYceKtZbjbGO/tEy7BExv0npoop7AdBFXC4LJEHYgSQIO5AEYQeSIOxAEtziOg5MnDixae3xxx8vznv++ecX65deemmx/vTTTxfr6D2GbAaSI+xAEoQdSIKwA0kQdiAJwg4kQdiBJDjPPs6deuqpxfqGDRuK9V27dhXrzz33XLE+ODjYtHbfffcV5+3lv83xhPPsQHKEHUiCsANJEHYgCcIOJEHYgSQIO5AE59mTGxgYKNYffPDBYv3YY49t+7uXLFlSrK9atapYHxoaKtaz4jw7kBxhB5Ig7EAShB1IgrADSRB2IAnCDiTBeXYUnXXWWcX6PffcU6xfdFH7g/0uX768WF+6dGmxvm3btra/+5us7fPsth+wvcP2phHTbrW9zfbGxuOyKpsFUL2xbMb/XNIlo0z/14iY1Xj8ptq2AFStZdgjYp2knT3oBUAXdXKAbpHt1xqb+Sc0e5PthbYHbTf/MTIAXddu2H8q6VRJsyQNSbq72RsjYkVEzI6I2W1+F4AKtBX2iNgeEQci4qCkn0maU21bAKrWVthtTx3xckDSpmbvBdAfWp5nt71a0gWSTpS0XdKPG69nSQpJ70n6YUS0vLmY8+zjz6RJk4r173//+01rre6Vt0c9XfyltWvXFuvz5s0r1serZufZjxjDjPNHmXx/xx0B6CkulwWSIOxAEoQdSIKwA0kQdiAJbnFFbb744oti/YgjyieL9u/fX6xffPHFTWvPP/98cd5vMn5KGkiOsANJEHYgCcIOJEHYgSQIO5AEYQeSaHnXG3I7++yzi/VrrrmmWD/nnHOa1lqdR29l8+bNxfq6des6+vzxhjU7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBefZxbubMmcX6okWLivWrrrqqWD/ppJMOu6exOnDgQLE+NFT+9fKDBw9W2c43Hmt2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUii5Xl22ydLWiVpioaHaF4RET+xPVnSQ5Kma3jY5msj4qPutZpXq3PZ8+ePNtDusFbn0adPn95OS5UYHBws1pcuXVqsr1mzpsp2xr2xrNn3S/q7iDhD0l9Lusn2GZJukfRsRJwm6dnGawB9qmXYI2IoIjY0nu+W9KakaZKukLSy8baVkq7sUo8AKnBY++y2p0v6jqT1kqZExKHrFT/Q8GY+gD415mvjbR8j6WFJP4qIT+z/H04qIqLZOG62F0pa2GmjADozpjW77SM1HPRfRMQjjcnbbU9t1KdK2jHavBGxIiJmR8TsKhoG0J6WYffwKvx+SW9GxD0jSmskLWg8XyDpserbA1CVlkM2254r6beSXpd06J7BJRreb/+VpFMkva/hU287W3xWyiGbp0wpH84444wzivV77723WD/99NMPu6eqrF+/vli/8847m9Yee6y8fuAW1fY0G7K55T57RPyXpFFnlnRRJ00B6B2uoAOSIOxAEoQdSIKwA0kQdiAJwg4kwU9Jj9HkyZOb1pYvX16cd9asWcX6jBkz2mmpEi+++GKxfvfddxfrTz31VLH+2WefHXZP6A7W7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQRJrz7Oeee26xvnjx4mJ9zpw5TWvTpk1rq6eqfPrpp01ry5YtK857++23F+t79+5tqyf0H9bsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5BEmvPsAwMDHdU7sXnz5mL9iSeeKNb3799frJfuOd+1a1dxXuTBmh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkhjL+OwnS1olaYqkkLQiIn5i+1ZJN0r6n8Zbl0TEb1p8Vsrx2YFeajY++1jCPlXS1IjYYPtYSS9LulLStZL2RMRdY22CsAPd1yzsLa+gi4ghSUON57ttvymp3p9mAXDYDmuf3fZ0Sd+RtL4xaZHt12w/YPuEJvMstD1oe7CzVgF0ouVm/JdvtI+R9IKkpRHxiO0pkj7U8H78P2p4U//6Fp/BZjzQZW3vs0uS7SMlPSHpqYi4Z5T6dElPRMRZLT6HsANd1izsLTfjbVvS/ZLeHBn0xoG7QwYkbeq0SQDdM5aj8XMl/VbS65IONiYvkTRf0iwNb8a/J+mHjYN5pc9izQ50WUeb8VUh7ED3tb0ZD2B8IOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTR6yGbP5T0/ojXJzam9aN+7a1f+5LorV1V9vYXzQo9vZ/9a19uD0bE7NoaKOjX3vq1L4ne2tWr3tiMB5Ig7EASdYd9Rc3fX9KvvfVrXxK9tasnvdW6zw6gd+peswPoEcIOJFFL2G1fYnuL7Xds31JHD83Yfs/267Y31j0+XWMMvR22N42YNtn2M7bfbvwddYy9mnq71fa2xrLbaPuymno72fZztjfbfsP2zY3ptS67Ql89WW4932e3PUHSW5LmSdoq6SVJ8yNic08bacL2e5JmR0TtF2DY/q6kPZJWHRpay/a/SNoZEXc0/qM8ISL+vk96u1WHOYx3l3prNsz436rGZVfl8OftqGPNPkfSOxHxbkTsk/RLSVfU0Effi4h1knZ+ZfIVklY2nq/U8D+WnmvSW1+IiKGI2NB4vlvSoWHGa112hb56oo6wT5P0hxGvt6q/xnsPSU/bftn2wrqbGcWUEcNsfSBpSp3NjKLlMN699JVhxvtm2bUz/HmnOED3dXMj4q8kXSrppsbmal+K4X2wfjp3+lNJp2p4DMAhSXfX2UxjmPGHJf0oIj4ZWatz2Y3SV0+WWx1h3ybp5BGvv9WY1hciYlvj7w5Jj2p4t6OfbD80gm7j746a+/lSRGyPiAMRcVDSz1TjsmsMM/6wpF9ExCONybUvu9H66tVyqyPsL0k6zfa3bR8l6QeS1tTQx9fYntg4cCLbEyV9T/03FPUaSQsazxdIeqzGXv5Ivwzj3WyYcdW87Gof/jwiev6QdJmGj8j/XtI/1NFDk75mSHq18Xij7t4krdbwZt3/avjYxg2S/kzSs5LelvSfkib3UW//ruGhvV/TcLCm1tTbXA1vor8maWPjcVndy67QV0+WG5fLAklwgA5IgrADSRB2IAnCDiRB2IEkCDuQBGEHkvg/aHSyPlCPUGAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(train_dataset.data[0], cmap='gray') # first image\n",
    "plt.title('%i' %train_dataset.targets[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "input_size = 28 * 28\n",
    "num_class = 10 #label: 0-9\n",
    "hidden_size = 500 # 500 nodes\n",
    "num_epoch = 5\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = test_dataset.targets\n",
    "test_y.shape # 10000 count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_class):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc_1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc_2 = nn.Linear(hidden_size, num_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc_1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc_2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (fc_1): Linear(in_features=784, out_features=500, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc_2): Linear(in_features=500, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Model(input_size=input_size, hidden_size=hidden_size, num_class=num_class)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = opt.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 100, Loss: 0.4368975758552551\n",
      "Epoch: 1, Batch: 200, Loss: 0.27841126918792725\n",
      "Epoch: 1, Batch: 300, Loss: 0.2847064137458801\n",
      "Epoch: 1, Batch: 400, Loss: 0.14572454988956451\n",
      "Epoch: 1, Batch: 500, Loss: 0.10392508655786514\n",
      "Epoch: 1, Batch: 600, Loss: 0.09990541636943817\n",
      "Epoch: 2, Batch: 100, Loss: 0.15500298142433167\n",
      "Epoch: 2, Batch: 200, Loss: 0.21916614472866058\n",
      "Epoch: 2, Batch: 300, Loss: 0.10973300784826279\n",
      "Epoch: 2, Batch: 400, Loss: 0.08755508065223694\n",
      "Epoch: 2, Batch: 500, Loss: 0.17618834972381592\n",
      "Epoch: 2, Batch: 600, Loss: 0.06609180569648743\n",
      "Epoch: 3, Batch: 100, Loss: 0.13912972807884216\n",
      "Epoch: 3, Batch: 200, Loss: 0.09400290250778198\n",
      "Epoch: 3, Batch: 300, Loss: 0.0839344710111618\n",
      "Epoch: 3, Batch: 400, Loss: 0.06767314672470093\n",
      "Epoch: 3, Batch: 500, Loss: 0.12001815438270569\n",
      "Epoch: 3, Batch: 600, Loss: 0.09195330739021301\n",
      "Epoch: 4, Batch: 100, Loss: 0.03426831588149071\n",
      "Epoch: 4, Batch: 200, Loss: 0.02733268216252327\n",
      "Epoch: 4, Batch: 300, Loss: 0.07544830441474915\n",
      "Epoch: 4, Batch: 400, Loss: 0.06599736213684082\n",
      "Epoch: 4, Batch: 500, Loss: 0.041493020951747894\n",
      "Epoch: 4, Batch: 600, Loss: 0.07262589037418365\n",
      "Epoch: 5, Batch: 100, Loss: 0.03398124873638153\n",
      "Epoch: 5, Batch: 200, Loss: 0.05379113554954529\n",
      "Epoch: 5, Batch: 300, Loss: 0.03754570707678795\n",
      "Epoch: 5, Batch: 400, Loss: 0.033424925059080124\n",
      "Epoch: 5, Batch: 500, Loss: 0.008823233656585217\n",
      "Epoch: 5, Batch: 600, Loss: 0.01045050099492073\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "for epoch in range(num_epoch):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # images are 100(batch_size) * 28*28 tensor.\n",
    "        images = Variable(images.view(-1, 28*28)) # -1 means 100 here\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(images) # forward pass\n",
    "        loss = loss_func(output, labels) # loss\n",
    "        \n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch: {}, Batch: {}, Loss: {}'.format(epoch+1, i+1, loss.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 98.00999999999999 %\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    labels = Variable(labels)\n",
    "    \n",
    "    # output is 100x10 matrix;\n",
    "    output = model(images)\n",
    "    \n",
    "    # 1 means max by column;\n",
    "    # _ is -> value; predicted -> label(index).\n",
    "    _, predicted = torch.max(output.data, 1) \n",
    "    \n",
    "    total += labels.size(0) # len; total is 100  here.\n",
    "    correct += (predicted == labels).sum()\n",
    "    \n",
    "print('accuracy: {} %'.format(float(correct)/ float(total) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images.data[0].view(28, 28), cmap='gray')\n",
    "plt.title(int(labels[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 method save model weight\n",
    "torch.save(model.state_dict(), 'model.pkl')\n",
    "model = Model(input_size, hidden_size, num_class)\n",
    "# load weight\n",
    "model.load_state_dict(torch.load('model.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 method save model\n",
    "torch.save(model, 'model2.pkl')\n",
    "model3 = torch.load('model2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other way building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=500, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=500, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_easyway = nn.Sequential(\n",
    "    nn.Linear(input_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size, num_class)\n",
    ")\n",
    "print(model_easyway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 100, Loss: 0.35251015424728394\n",
      "Epoch: 1, Batch: 200, Loss: 0.31007587909698486\n",
      "Epoch: 1, Batch: 300, Loss: 0.21771490573883057\n",
      "Epoch: 1, Batch: 400, Loss: 0.14278611540794373\n",
      "Epoch: 1, Batch: 500, Loss: 0.2827369272708893\n",
      "Epoch: 1, Batch: 600, Loss: 0.08428749442100525\n",
      "Epoch: 2, Batch: 100, Loss: 0.09439954161643982\n",
      "Epoch: 2, Batch: 200, Loss: 0.19932690262794495\n",
      "Epoch: 2, Batch: 300, Loss: 0.22997543215751648\n",
      "Epoch: 2, Batch: 400, Loss: 0.07815054059028625\n",
      "Epoch: 2, Batch: 500, Loss: 0.05686445161700249\n",
      "Epoch: 2, Batch: 600, Loss: 0.06547123193740845\n",
      "Epoch: 3, Batch: 100, Loss: 0.0334070585668087\n",
      "Epoch: 3, Batch: 200, Loss: 0.0350540429353714\n",
      "Epoch: 3, Batch: 300, Loss: 0.07758684456348419\n",
      "Epoch: 3, Batch: 400, Loss: 0.06483740359544754\n",
      "Epoch: 3, Batch: 500, Loss: 0.06323257833719254\n",
      "Epoch: 3, Batch: 600, Loss: 0.06947433203458786\n",
      "Epoch: 4, Batch: 100, Loss: 0.036823540925979614\n",
      "Epoch: 4, Batch: 200, Loss: 0.04389040917158127\n",
      "Epoch: 4, Batch: 300, Loss: 0.032566580921411514\n",
      "Epoch: 4, Batch: 400, Loss: 0.01773233339190483\n",
      "Epoch: 4, Batch: 500, Loss: 0.02207851968705654\n",
      "Epoch: 4, Batch: 600, Loss: 0.10990441590547562\n",
      "Epoch: 5, Batch: 100, Loss: 0.0651884526014328\n",
      "Epoch: 5, Batch: 200, Loss: 0.04977795481681824\n",
      "Epoch: 5, Batch: 300, Loss: 0.017512785270810127\n",
      "Epoch: 5, Batch: 400, Loss: 0.018363608047366142\n",
      "Epoch: 5, Batch: 500, Loss: 0.05875054746866226\n",
      "Epoch: 5, Batch: 600, Loss: 0.03894755244255066\n"
     ]
    }
   ],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = opt.Adam(model_easyway.parameters(), lr=learning_rate)\n",
    "\n",
    "# train model\n",
    "for epoch in range(num_epoch):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # images are 100(batch_size) * 28*28 tensor.\n",
    "        images = Variable(images.view(-1, 28*28)) # -1 means 100 here\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model_easyway(images) # forward pass\n",
    "        loss = loss_func(output, labels) # loss\n",
    "        \n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch: {}, Batch: {}, Loss: {}'.format(epoch+1, i+1, loss.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 97.82 %\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    labels = Variable(labels)\n",
    "    \n",
    "    # output is 100x10 matrix;\n",
    "    output = model_easyway(images)\n",
    "    \n",
    "    # 1 means max by column;\n",
    "    # _ is -> value; predicted -> label(index).\n",
    "    _, predicted = torch.max(output.data, 1) \n",
    "    \n",
    "    total += labels.size(0) # len; total is 100  here.\n",
    "    correct += (predicted == labels).sum()\n",
    "    \n",
    "print('accuracy: {} %'.format(float(correct)/ float(total) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
