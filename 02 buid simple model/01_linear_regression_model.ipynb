{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02 build simple model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOvPEYVz2mTX"
      },
      "source": [
        "batch_n = 100\n",
        "in_features = 3\n",
        "out_features = 1\n",
        "epoch_n = 100\n",
        "learning_rate = 0.001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtyiHg6R3MVx"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t88ZyGuw2yUM",
        "outputId": "69ea76f2-6b83-44d9-936e-5239ad148d5f"
      },
      "source": [
        "# y = 3x_1 + 5x_2 + 1x_3\n",
        "x = torch.rand(batch_n, in_features)\n",
        "c = torch.Tensor([[3.], [5.], [1]])\n",
        "y = x.mm(c)\n",
        "y = y.add(torch.rand(batch_n, out_features))\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5.0333],\n",
              "        [7.1447],\n",
              "        [5.7842],\n",
              "        [2.2990],\n",
              "        [7.5939],\n",
              "        [5.8820],\n",
              "        [4.4825],\n",
              "        [7.6891],\n",
              "        [4.0879],\n",
              "        [4.4130],\n",
              "        [4.1978],\n",
              "        [3.3543],\n",
              "        [5.8353],\n",
              "        [6.9609],\n",
              "        [8.1401],\n",
              "        [4.9527],\n",
              "        [5.4089],\n",
              "        [3.1986],\n",
              "        [6.5651],\n",
              "        [4.5649],\n",
              "        [4.2437],\n",
              "        [5.2432],\n",
              "        [5.7944],\n",
              "        [4.2027],\n",
              "        [3.5034],\n",
              "        [2.6826],\n",
              "        [2.3562],\n",
              "        [6.8675],\n",
              "        [4.1786],\n",
              "        [4.4298],\n",
              "        [5.1605],\n",
              "        [4.0313],\n",
              "        [2.8938],\n",
              "        [3.6209],\n",
              "        [4.6013],\n",
              "        [5.9889],\n",
              "        [5.8564],\n",
              "        [4.6107],\n",
              "        [6.5970],\n",
              "        [5.6425],\n",
              "        [6.1359],\n",
              "        [5.5072],\n",
              "        [3.6296],\n",
              "        [4.4670],\n",
              "        [4.9039],\n",
              "        [5.3955],\n",
              "        [6.9775],\n",
              "        [5.9400],\n",
              "        [4.3074],\n",
              "        [1.7405],\n",
              "        [7.3625],\n",
              "        [2.5129],\n",
              "        [5.7464],\n",
              "        [1.1441],\n",
              "        [2.9522],\n",
              "        [8.6732],\n",
              "        [3.7963],\n",
              "        [6.0461],\n",
              "        [5.7067],\n",
              "        [7.5338],\n",
              "        [5.9523],\n",
              "        [6.1150],\n",
              "        [5.8963],\n",
              "        [8.4075],\n",
              "        [7.0726],\n",
              "        [1.7740],\n",
              "        [2.8913],\n",
              "        [8.7544],\n",
              "        [5.1851],\n",
              "        [6.6925],\n",
              "        [2.7427],\n",
              "        [5.2394],\n",
              "        [5.7847],\n",
              "        [5.8771],\n",
              "        [4.7503],\n",
              "        [2.4509],\n",
              "        [3.9888],\n",
              "        [5.4718],\n",
              "        [5.4830],\n",
              "        [2.3811],\n",
              "        [3.1764],\n",
              "        [2.6519],\n",
              "        [4.3587],\n",
              "        [3.9501],\n",
              "        [4.5743],\n",
              "        [5.6294],\n",
              "        [2.1113],\n",
              "        [7.5068],\n",
              "        [3.1750],\n",
              "        [6.0319],\n",
              "        [4.5494],\n",
              "        [4.0602],\n",
              "        [4.6851],\n",
              "        [3.3023],\n",
              "        [7.5995],\n",
              "        [2.3639],\n",
              "        [2.6310],\n",
              "        [5.5667],\n",
              "        [7.8178],\n",
              "        [1.4241]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwRKxzUw4WLx"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "R6YYOAH24tul",
        "outputId": "027fc10a-a1d7-464c-b7d1-e888f350fdaa"
      },
      "source": [
        "plt.figure()\n",
        "plt.scatter(x[:, 1], y)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QJDvUet5YvB",
        "outputId": "63c13b85-94f9-4bb8-f440-f37c66832156"
      },
      "source": [
        "w = torch.rand(in_features, out_features)\n",
        "w"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1257],\n",
              "        [0.0126],\n",
              "        [0.2300]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2pSnQK16EPr",
        "outputId": "9b4884b2-4633-44ad-d1ec-652ab086b2ea"
      },
      "source": [
        "for epoch in range(epoch_n):\n",
        "  y_pred = x.mm(w)\n",
        "  loss = (y_pred - y).pow(2).sum() # MSE\n",
        "  print('Epoch:{} Loss:{:.4f}'.format(epoch, loss))\n",
        "\n",
        "  grad_y_pred = 2 * (y_pred - y)\n",
        "  grad_w = x.t().mm(grad_y_pred)\n",
        "  \n",
        "  w -= learning_rate * grad_w "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:0 Loss:2525.8342\n",
            "Epoch:1 Loss:1798.9587\n",
            "Epoch:2 Loss:1287.9189\n",
            "Epoch:3 Loss:928.4240\n",
            "Epoch:4 Loss:675.3396\n",
            "Epoch:5 Loss:496.9810\n",
            "Epoch:6 Loss:371.1041\n",
            "Epoch:7 Loss:282.0928\n",
            "Epoch:8 Loss:218.9835\n",
            "Epoch:9 Loss:174.0791\n",
            "Epoch:10 Loss:141.9754\n",
            "Epoch:11 Loss:118.8778\n",
            "Epoch:12 Loss:102.1219\n",
            "Epoch:13 Loss:89.8365\n",
            "Epoch:14 Loss:80.7075\n",
            "Epoch:15 Loss:73.8116\n",
            "Epoch:16 Loss:68.5002\n",
            "Epoch:17 Loss:64.3173\n",
            "Epoch:18 Loss:60.9422\n",
            "Epoch:19 Loss:58.1494\n",
            "Epoch:20 Loss:55.7799\n",
            "Epoch:21 Loss:53.7216\n",
            "Epoch:22 Loss:51.8953\n",
            "Epoch:23 Loss:50.2451\n",
            "Epoch:24 Loss:48.7311\n",
            "Epoch:25 Loss:47.3250\n",
            "Epoch:26 Loss:46.0063\n",
            "Epoch:27 Loss:44.7606\n",
            "Epoch:28 Loss:43.5769\n",
            "Epoch:29 Loss:42.4475\n",
            "Epoch:30 Loss:41.3663\n",
            "Epoch:31 Loss:40.3290\n",
            "Epoch:32 Loss:39.3321\n",
            "Epoch:33 Loss:38.3726\n",
            "Epoch:34 Loss:37.4484\n",
            "Epoch:35 Loss:36.5576\n",
            "Epoch:36 Loss:35.6985\n",
            "Epoch:37 Loss:34.8697\n",
            "Epoch:38 Loss:34.0698\n",
            "Epoch:39 Loss:33.2978\n",
            "Epoch:40 Loss:32.5526\n",
            "Epoch:41 Loss:31.8331\n",
            "Epoch:42 Loss:31.1384\n",
            "Epoch:43 Loss:30.4676\n",
            "Epoch:44 Loss:29.8199\n",
            "Epoch:45 Loss:29.1944\n",
            "Epoch:46 Loss:28.5904\n",
            "Epoch:47 Loss:28.0071\n",
            "Epoch:48 Loss:27.4438\n",
            "Epoch:49 Loss:26.8997\n",
            "Epoch:50 Loss:26.3744\n",
            "Epoch:51 Loss:25.8670\n",
            "Epoch:52 Loss:25.3769\n",
            "Epoch:53 Loss:24.9037\n",
            "Epoch:54 Loss:24.4466\n",
            "Epoch:55 Loss:24.0052\n",
            "Epoch:56 Loss:23.5788\n",
            "Epoch:57 Loss:23.1671\n",
            "Epoch:58 Loss:22.7694\n",
            "Epoch:59 Loss:22.3853\n",
            "Epoch:60 Loss:22.0143\n",
            "Epoch:61 Loss:21.6560\n",
            "Epoch:62 Loss:21.3099\n",
            "Epoch:63 Loss:20.9757\n",
            "Epoch:64 Loss:20.6528\n",
            "Epoch:65 Loss:20.3410\n",
            "Epoch:66 Loss:20.0398\n",
            "Epoch:67 Loss:19.7489\n",
            "Epoch:68 Loss:19.4680\n",
            "Epoch:69 Loss:19.1966\n",
            "Epoch:70 Loss:18.9344\n",
            "Epoch:71 Loss:18.6812\n",
            "Epoch:72 Loss:18.4367\n",
            "Epoch:73 Loss:18.2004\n",
            "Epoch:74 Loss:17.9722\n",
            "Epoch:75 Loss:17.7518\n",
            "Epoch:76 Loss:17.5389\n",
            "Epoch:77 Loss:17.3333\n",
            "Epoch:78 Loss:17.1346\n",
            "Epoch:79 Loss:16.9427\n",
            "Epoch:80 Loss:16.7574\n",
            "Epoch:81 Loss:16.5783\n",
            "Epoch:82 Loss:16.4054\n",
            "Epoch:83 Loss:16.2383\n",
            "Epoch:84 Loss:16.0769\n",
            "Epoch:85 Loss:15.9210\n",
            "Epoch:86 Loss:15.7704\n",
            "Epoch:87 Loss:15.6249\n",
            "Epoch:88 Loss:15.4843\n",
            "Epoch:89 Loss:15.3486\n",
            "Epoch:90 Loss:15.2174\n",
            "Epoch:91 Loss:15.0907\n",
            "Epoch:92 Loss:14.9683\n",
            "Epoch:93 Loss:14.8500\n",
            "Epoch:94 Loss:14.7358\n",
            "Epoch:95 Loss:14.6255\n",
            "Epoch:96 Loss:14.5188\n",
            "Epoch:97 Loss:14.4158\n",
            "Epoch:98 Loss:14.3163\n",
            "Epoch:99 Loss:14.2202\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_roQribv82UJ",
        "outputId": "a181410f-3355-4c09-a72c-47a71bafb924"
      },
      "source": [
        "w"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3.2519],\n",
              "        [4.9639],\n",
              "        [1.7646]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3kgdLjQ87Q9"
      },
      "source": [
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ranqs8PQ9rHQ"
      },
      "source": [
        "Vx = Variable(x, requires_grad=False)\n",
        "Vy = Variable(y, requires_grad=False)\n",
        "Vw = Variable(torch.rand(in_features, out_features), requires_grad=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g87IoqM7-xSk",
        "outputId": "e13e13df-220f-4b28-ff82-865ce314c832"
      },
      "source": [
        "for epoch in range(epoch_n):\n",
        "  y_pred = Vx.mm(Vw)\n",
        "  loss = (y_pred - Vy).pow(2).sum() # MSE\n",
        "  print('Epoch:{} Loss:{:.4f}'.format(epoch, loss))\n",
        "\n",
        "  loss.backward()\n",
        "  \n",
        "  Vw.data -= learning_rate * Vw.grad.data\n",
        "\n",
        "  Vw.grad.data.zero_()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:0 Loss:2225.6851\n",
            "Epoch:1 Loss:1588.3502\n",
            "Epoch:2 Loss:1140.1626\n",
            "Epoch:3 Loss:824.7841\n",
            "Epoch:4 Loss:602.6645\n",
            "Epoch:5 Loss:446.0381\n",
            "Epoch:6 Loss:335.4124\n",
            "Epoch:7 Loss:257.1028\n",
            "Epoch:8 Loss:201.5017\n",
            "Epoch:9 Loss:161.8639\n",
            "Epoch:10 Loss:133.4533\n",
            "Epoch:11 Loss:112.9445\n",
            "Epoch:12 Loss:98.0023\n",
            "Epoch:13 Loss:86.9867\n",
            "Epoch:14 Loss:78.7458\n",
            "Epoch:15 Loss:72.4704\n",
            "Epoch:16 Loss:67.5916\n",
            "Epoch:17 Loss:63.7097\n",
            "Epoch:18 Loss:60.5433\n",
            "Epoch:19 Loss:57.8945\n",
            "Epoch:20 Loss:55.6237\n",
            "Epoch:21 Loss:53.6326\n",
            "Epoch:22 Loss:51.8514\n",
            "Epoch:23 Loss:50.2308\n",
            "Epoch:24 Loss:48.7358\n",
            "Epoch:25 Loss:47.3413\n",
            "Epoch:26 Loss:46.0291\n",
            "Epoch:27 Loss:44.7864\n",
            "Epoch:28 Loss:43.6034\n",
            "Epoch:29 Loss:42.4730\n",
            "Epoch:30 Loss:41.3900\n",
            "Epoch:31 Loss:40.3501\n",
            "Epoch:32 Loss:39.3503\n",
            "Epoch:33 Loss:38.3877\n",
            "Epoch:34 Loss:37.4604\n",
            "Epoch:35 Loss:36.5664\n",
            "Epoch:36 Loss:35.7042\n",
            "Epoch:37 Loss:34.8724\n",
            "Epoch:38 Loss:34.0697\n",
            "Epoch:39 Loss:33.2950\n",
            "Epoch:40 Loss:32.5472\n",
            "Epoch:41 Loss:31.8254\n",
            "Epoch:42 Loss:31.1284\n",
            "Epoch:43 Loss:30.4556\n",
            "Epoch:44 Loss:29.8059\n",
            "Epoch:45 Loss:29.1786\n",
            "Epoch:46 Loss:28.5730\n",
            "Epoch:47 Loss:27.9881\n",
            "Epoch:48 Loss:27.4234\n",
            "Epoch:49 Loss:26.8781\n",
            "Epoch:50 Loss:26.3515\n",
            "Epoch:51 Loss:25.8430\n",
            "Epoch:52 Loss:25.3520\n",
            "Epoch:53 Loss:24.8778\n",
            "Epoch:54 Loss:24.4200\n",
            "Epoch:55 Loss:23.9778\n",
            "Epoch:56 Loss:23.5508\n",
            "Epoch:57 Loss:23.1385\n",
            "Epoch:58 Loss:22.7403\n",
            "Epoch:59 Loss:22.3558\n",
            "Epoch:60 Loss:21.9844\n",
            "Epoch:61 Loss:21.6258\n",
            "Epoch:62 Loss:21.2795\n",
            "Epoch:63 Loss:20.9451\n",
            "Epoch:64 Loss:20.6221\n",
            "Epoch:65 Loss:20.3102\n",
            "Epoch:66 Loss:20.0089\n",
            "Epoch:67 Loss:19.7180\n",
            "Epoch:68 Loss:19.4370\n",
            "Epoch:69 Loss:19.1657\n",
            "Epoch:70 Loss:18.9036\n",
            "Epoch:71 Loss:18.6505\n",
            "Epoch:72 Loss:18.4061\n",
            "Epoch:73 Loss:18.1700\n",
            "Epoch:74 Loss:17.9420\n",
            "Epoch:75 Loss:17.7218\n",
            "Epoch:76 Loss:17.5091\n",
            "Epoch:77 Loss:17.3037\n",
            "Epoch:78 Loss:17.1053\n",
            "Epoch:79 Loss:16.9137\n",
            "Epoch:80 Loss:16.7287\n",
            "Epoch:81 Loss:16.5499\n",
            "Epoch:82 Loss:16.3773\n",
            "Epoch:83 Loss:16.2105\n",
            "Epoch:84 Loss:16.0495\n",
            "Epoch:85 Loss:15.8939\n",
            "Epoch:86 Loss:15.7437\n",
            "Epoch:87 Loss:15.5985\n",
            "Epoch:88 Loss:15.4584\n",
            "Epoch:89 Loss:15.3230\n",
            "Epoch:90 Loss:15.1922\n",
            "Epoch:91 Loss:15.0658\n",
            "Epoch:92 Loss:14.9438\n",
            "Epoch:93 Loss:14.8260\n",
            "Epoch:94 Loss:14.7121\n",
            "Epoch:95 Loss:14.6022\n",
            "Epoch:96 Loss:14.4959\n",
            "Epoch:97 Loss:14.3933\n",
            "Epoch:98 Loss:14.2942\n",
            "Epoch:99 Loss:14.1985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeb1op-j_s_2",
        "outputId": "aa7f8837-1e10-4220-e61b-5f24f74bc3d4"
      },
      "source": [
        "Vw.data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3.2622],\n",
              "        [4.9609],\n",
              "        [1.7553]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YyWYYlUjZsT"
      },
      "source": [
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EO6yQ4mpjgvD"
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "  \n",
        "  def forward(self, x, w):\n",
        "    y_pred = x.mm(w)\n",
        "    return y_pred\n",
        "  \n",
        "  def backward(self):\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaZrSetAtqdW"
      },
      "source": [
        "model = Model()\n",
        "Vw = Variable(torch.rand(in_features, out_features), requires_grad=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_FX6h3ytu6i",
        "outputId": "6ce317d5-13f4-464c-8849-00df62c5e741"
      },
      "source": [
        "for epoch in range(epoch_n):\n",
        "  y_pred = model(Vx, Vw)\n",
        "  loss = (y_pred - Vy).pow(2).sum() # MSE\n",
        "  print('Epoch:{} Loss:{:.4f}'.format(epoch, loss))\n",
        "\n",
        "  loss.backward()\n",
        "  \n",
        "  Vw.data -= learning_rate * Vw.grad.data\n",
        "\n",
        "  Vw.grad.data.zero_()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:0 Loss:1752.4587\n",
            "Epoch:1 Loss:1252.9465\n",
            "Epoch:2 Loss:901.6400\n",
            "Epoch:3 Loss:654.3964\n",
            "Epoch:4 Loss:480.2265\n",
            "Epoch:5 Loss:357.3752\n",
            "Epoch:6 Loss:270.5693\n",
            "Epoch:7 Loss:209.0867\n",
            "Epoch:8 Loss:165.3993\n",
            "Epoch:9 Loss:134.2220\n",
            "Epoch:10 Loss:111.8441\n",
            "Epoch:11 Loss:95.6597\n",
            "Epoch:12 Loss:83.8394\n",
            "Epoch:13 Loss:75.0979\n",
            "Epoch:14 Loss:68.5328\n",
            "Epoch:15 Loss:63.5099\n",
            "Epoch:16 Loss:59.5836\n",
            "Epoch:17 Loss:56.4405\n",
            "Epoch:18 Loss:53.8602\n",
            "Epoch:19 Loss:51.6875\n",
            "Epoch:20 Loss:49.8132\n",
            "Epoch:21 Loss:48.1600\n",
            "Epoch:22 Loss:46.6734\n",
            "Epoch:23 Loss:45.3146\n",
            "Epoch:24 Loss:44.0561\n",
            "Epoch:25 Loss:42.8783\n",
            "Epoch:26 Loss:41.7670\n",
            "Epoch:27 Loss:40.7119\n",
            "Epoch:28 Loss:39.7054\n",
            "Epoch:29 Loss:38.7421\n",
            "Epoch:30 Loss:37.8175\n",
            "Epoch:31 Loss:36.9286\n",
            "Epoch:32 Loss:36.0727\n",
            "Epoch:33 Loss:35.2477\n",
            "Epoch:34 Loss:34.4519\n",
            "Epoch:35 Loss:33.6839\n",
            "Epoch:36 Loss:32.9424\n",
            "Epoch:37 Loss:32.2263\n",
            "Epoch:38 Loss:31.5346\n",
            "Epoch:39 Loss:30.8662\n",
            "Epoch:40 Loss:30.2204\n",
            "Epoch:41 Loss:29.5963\n",
            "Epoch:42 Loss:28.9932\n",
            "Epoch:43 Loss:28.4104\n",
            "Epoch:44 Loss:27.8470\n",
            "Epoch:45 Loss:27.3025\n",
            "Epoch:46 Loss:26.7763\n",
            "Epoch:47 Loss:26.2676\n",
            "Epoch:48 Loss:25.7759\n",
            "Epoch:49 Loss:25.3007\n",
            "Epoch:50 Loss:24.8413\n",
            "Epoch:51 Loss:24.3973\n",
            "Epoch:52 Loss:23.9681\n",
            "Epoch:53 Loss:23.5532\n",
            "Epoch:54 Loss:23.1522\n",
            "Epoch:55 Loss:22.7645\n",
            "Epoch:56 Loss:22.3898\n",
            "Epoch:57 Loss:22.0276\n",
            "Epoch:58 Loss:21.6774\n",
            "Epoch:59 Loss:21.3389\n",
            "Epoch:60 Loss:21.0117\n",
            "Epoch:61 Loss:20.6954\n",
            "Epoch:62 Loss:20.3896\n",
            "Epoch:63 Loss:20.0940\n",
            "Epoch:64 Loss:19.8083\n",
            "Epoch:65 Loss:19.5321\n",
            "Epoch:66 Loss:19.2650\n",
            "Epoch:67 Loss:19.0069\n",
            "Epoch:68 Loss:18.7573\n",
            "Epoch:69 Loss:18.5161\n",
            "Epoch:70 Loss:18.2828\n",
            "Epoch:71 Loss:18.0573\n",
            "Epoch:72 Loss:17.8394\n",
            "Epoch:73 Loss:17.6286\n",
            "Epoch:74 Loss:17.4249\n",
            "Epoch:75 Loss:17.2279\n",
            "Epoch:76 Loss:17.0375\n",
            "Epoch:77 Loss:16.8534\n",
            "Epoch:78 Loss:16.6754\n",
            "Epoch:79 Loss:16.5034\n",
            "Epoch:80 Loss:16.3370\n",
            "Epoch:81 Loss:16.1762\n",
            "Epoch:82 Loss:16.0207\n",
            "Epoch:83 Loss:15.8703\n",
            "Epoch:84 Loss:15.7250\n",
            "Epoch:85 Loss:15.5844\n",
            "Epoch:86 Loss:15.4486\n",
            "Epoch:87 Loss:15.3172\n",
            "Epoch:88 Loss:15.1902\n",
            "Epoch:89 Loss:15.0674\n",
            "Epoch:90 Loss:14.9487\n",
            "Epoch:91 Loss:14.8338\n",
            "Epoch:92 Loss:14.7228\n",
            "Epoch:93 Loss:14.6155\n",
            "Epoch:94 Loss:14.5118\n",
            "Epoch:95 Loss:14.4114\n",
            "Epoch:96 Loss:14.3144\n",
            "Epoch:97 Loss:14.2206\n",
            "Epoch:98 Loss:14.1299\n",
            "Epoch:99 Loss:14.0422\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0p63IaTauEYe",
        "outputId": "331d47f4-0ac9-4c12-bbe5-c81260ba8660"
      },
      "source": [
        "Vw"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3.1850],\n",
              "        [5.0133],\n",
              "        [1.7961]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2SMGKpkuOta"
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "    self.linear = nn.Linear(in_features, out_features, False)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    y_pred = self.linear(x)\n",
        "    return y_pred\n",
        "  \n",
        "  def backward(self):\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qj7gdUF7sWSD",
        "outputId": "4cd519c6-9f6f-4648-bf0d-024ee101693c"
      },
      "source": [
        "model = Model()\n",
        "loss_fn = nn.MSELoss()\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model(\n",
            "  (linear): Linear(in_features=3, out_features=1, bias=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6_DA5S2spKf",
        "outputId": "1852f918-64e8-4b37-c211-2423efab668e"
      },
      "source": [
        "for epoch in range(epoch_n*100):\n",
        "  y_pred = model(x)\n",
        "  loss = loss_fn(y_pred, y)\n",
        "  if (epoch + 1) % 100 == 0 :\n",
        "    print('Epoch:{} Loss:{:.4f}'.format(epoch, loss))\n",
        "\n",
        "  model.zero_grad()\n",
        "  loss.backward()\n",
        "  \n",
        "  for parameter in model.parameters():\n",
        "    parameter.data -= learning_rate * parameter.grad.data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:99 Loss:15.6632\n",
            "Epoch:199 Loss:11.5217\n",
            "Epoch:299 Loss:8.5222\n",
            "Epoch:399 Loss:6.3484\n",
            "Epoch:499 Loss:4.7716\n",
            "Epoch:599 Loss:3.6267\n",
            "Epoch:699 Loss:2.7940\n",
            "Epoch:799 Loss:2.1873\n",
            "Epoch:899 Loss:1.7441\n",
            "Epoch:999 Loss:1.4191\n",
            "Epoch:1099 Loss:1.1799\n",
            "Epoch:1199 Loss:1.0027\n",
            "Epoch:1299 Loss:0.8706\n",
            "Epoch:1399 Loss:0.7712\n",
            "Epoch:1499 Loss:0.6955\n",
            "Epoch:1599 Loss:0.6372\n",
            "Epoch:1699 Loss:0.5915\n",
            "Epoch:1799 Loss:0.5550\n",
            "Epoch:1899 Loss:0.5254\n",
            "Epoch:1999 Loss:0.5008\n",
            "Epoch:2099 Loss:0.4800\n",
            "Epoch:2199 Loss:0.4619\n",
            "Epoch:2299 Loss:0.4460\n",
            "Epoch:2399 Loss:0.4318\n",
            "Epoch:2499 Loss:0.4188\n",
            "Epoch:2599 Loss:0.4069\n",
            "Epoch:2699 Loss:0.3957\n",
            "Epoch:2799 Loss:0.3853\n",
            "Epoch:2899 Loss:0.3754\n",
            "Epoch:2999 Loss:0.3661\n",
            "Epoch:3099 Loss:0.3572\n",
            "Epoch:3199 Loss:0.3486\n",
            "Epoch:3299 Loss:0.3404\n",
            "Epoch:3399 Loss:0.3326\n",
            "Epoch:3499 Loss:0.3250\n",
            "Epoch:3599 Loss:0.3177\n",
            "Epoch:3699 Loss:0.3107\n",
            "Epoch:3799 Loss:0.3040\n",
            "Epoch:3899 Loss:0.2975\n",
            "Epoch:3999 Loss:0.2912\n",
            "Epoch:4099 Loss:0.2851\n",
            "Epoch:4199 Loss:0.2793\n",
            "Epoch:4299 Loss:0.2736\n",
            "Epoch:4399 Loss:0.2682\n",
            "Epoch:4499 Loss:0.2629\n",
            "Epoch:4599 Loss:0.2578\n",
            "Epoch:4699 Loss:0.2529\n",
            "Epoch:4799 Loss:0.2482\n",
            "Epoch:4899 Loss:0.2436\n",
            "Epoch:4999 Loss:0.2392\n",
            "Epoch:5099 Loss:0.2349\n",
            "Epoch:5199 Loss:0.2308\n",
            "Epoch:5299 Loss:0.2269\n",
            "Epoch:5399 Loss:0.2230\n",
            "Epoch:5499 Loss:0.2193\n",
            "Epoch:5599 Loss:0.2157\n",
            "Epoch:5699 Loss:0.2123\n",
            "Epoch:5799 Loss:0.2089\n",
            "Epoch:5899 Loss:0.2057\n",
            "Epoch:5999 Loss:0.2026\n",
            "Epoch:6099 Loss:0.1996\n",
            "Epoch:6199 Loss:0.1967\n",
            "Epoch:6299 Loss:0.1939\n",
            "Epoch:6399 Loss:0.1912\n",
            "Epoch:6499 Loss:0.1886\n",
            "Epoch:6599 Loss:0.1861\n",
            "Epoch:6699 Loss:0.1836\n",
            "Epoch:6799 Loss:0.1813\n",
            "Epoch:6899 Loss:0.1790\n",
            "Epoch:6999 Loss:0.1768\n",
            "Epoch:7099 Loss:0.1747\n",
            "Epoch:7199 Loss:0.1726\n",
            "Epoch:7299 Loss:0.1707\n",
            "Epoch:7399 Loss:0.1688\n",
            "Epoch:7499 Loss:0.1669\n",
            "Epoch:7599 Loss:0.1651\n",
            "Epoch:7699 Loss:0.1634\n",
            "Epoch:7799 Loss:0.1617\n",
            "Epoch:7899 Loss:0.1601\n",
            "Epoch:7999 Loss:0.1586\n",
            "Epoch:8099 Loss:0.1571\n",
            "Epoch:8199 Loss:0.1557\n",
            "Epoch:8299 Loss:0.1543\n",
            "Epoch:8399 Loss:0.1529\n",
            "Epoch:8499 Loss:0.1516\n",
            "Epoch:8599 Loss:0.1504\n",
            "Epoch:8699 Loss:0.1491\n",
            "Epoch:8799 Loss:0.1480\n",
            "Epoch:8899 Loss:0.1468\n",
            "Epoch:8999 Loss:0.1457\n",
            "Epoch:9099 Loss:0.1447\n",
            "Epoch:9199 Loss:0.1437\n",
            "Epoch:9299 Loss:0.1427\n",
            "Epoch:9399 Loss:0.1417\n",
            "Epoch:9499 Loss:0.1408\n",
            "Epoch:9599 Loss:0.1399\n",
            "Epoch:9699 Loss:0.1391\n",
            "Epoch:9799 Loss:0.1382\n",
            "Epoch:9899 Loss:0.1374\n",
            "Epoch:9999 Loss:0.1367\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAX-a00Tzqr2",
        "outputId": "b078098d-3904-4578-b678-c69897cb3cb5"
      },
      "source": [
        "for parameter in model.parameters():\n",
        "  print(parameter.data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3.2872, 4.9865, 1.7016]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPiDwDlj3Vnm"
      },
      "source": [
        " model = Model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJycQEUT5t5H"
      },
      "source": [
        "import torch.optim as opt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78XjD1OF5348"
      },
      "source": [
        "optimizer = opt.SGD(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYUkoQl26r3n"
      },
      "source": [
        "for epoch in range(epoch_n*100):\n",
        "  y_pred = model(x)\n",
        "  loss = loss_fn(y_pred, y)\n",
        "  if (epoch + 1) % 100 == 0 :\n",
        "    print('Epoch:{} Loss:{:.4f}'.format(epoch, loss))\n",
        "\n",
        "  model.zero_grad()\n",
        "  loss.backward()\n",
        "  \n",
        "  optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcYtFDGI68H_",
        "outputId": "87bd44c9-8717-4b26-a9d9-9b49a767266c"
      },
      "source": [
        "for parameter in model.parameters():\n",
        "  print(parameter.data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3.2373, 4.9754, 1.7708]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP2huU-T8bHy"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uM1l0WDa8t7q",
        "outputId": "bea0b750-546c-40e4-d010-3ab2f8dd40da"
      },
      "source": [
        "npy = y.numpy()\n",
        "bins = np.array([npy.mean()])\n",
        "idx = np.digitize(npy, bins)\n",
        "cy = torch.from_numpy(idx)\n",
        "cy = cy.float()\n",
        "print(cy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MulCIXlR9Y6t"
      },
      "source": [
        "Vx = Variable(x, requires_grad=False)\n",
        "Vy = Variable(cy, requires_grad=False)\n",
        "Vw = Variable(torch.rand(in_features, out_features), requires_grad=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLUyvRlS-C0R",
        "outputId": "330c1932-650a-48b7-a359-181000baec60"
      },
      "source": [
        "for epoch in range(epoch_n*1000):\n",
        "  y_pred = torch.sigmoid(Vx.mm(Vw))\n",
        "  loss = (-1.0*(\n",
        "              Vy*torch.log10(y_pred) + (1.0-Vy) * torch.log10(1.0-y_pred)\n",
        "          )).mean()\n",
        "  if (epoch + 1)%1000 == 0:\n",
        "    print('Epoch:{} Loss:{:.4f}'.format(epoch, loss))\n",
        "\n",
        "  loss.backward()\n",
        "  \n",
        "  Vw.data -= learning_rate * Vw.grad.data\n",
        "\n",
        "  Vw.grad.data.zero_()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:999 Loss:0.3223\n",
            "Epoch:1999 Loss:0.3169\n",
            "Epoch:2999 Loss:0.3121\n",
            "Epoch:3999 Loss:0.3076\n",
            "Epoch:4999 Loss:0.3036\n",
            "Epoch:5999 Loss:0.3000\n",
            "Epoch:6999 Loss:0.2966\n",
            "Epoch:7999 Loss:0.2936\n",
            "Epoch:8999 Loss:0.2909\n",
            "Epoch:9999 Loss:0.2884\n",
            "Epoch:10999 Loss:0.2862\n",
            "Epoch:11999 Loss:0.2842\n",
            "Epoch:12999 Loss:0.2823\n",
            "Epoch:13999 Loss:0.2806\n",
            "Epoch:14999 Loss:0.2790\n",
            "Epoch:15999 Loss:0.2776\n",
            "Epoch:16999 Loss:0.2763\n",
            "Epoch:17999 Loss:0.2750\n",
            "Epoch:18999 Loss:0.2739\n",
            "Epoch:19999 Loss:0.2728\n",
            "Epoch:20999 Loss:0.2718\n",
            "Epoch:21999 Loss:0.2709\n",
            "Epoch:22999 Loss:0.2700\n",
            "Epoch:23999 Loss:0.2692\n",
            "Epoch:24999 Loss:0.2684\n",
            "Epoch:25999 Loss:0.2676\n",
            "Epoch:26999 Loss:0.2669\n",
            "Epoch:27999 Loss:0.2662\n",
            "Epoch:28999 Loss:0.2655\n",
            "Epoch:29999 Loss:0.2649\n",
            "Epoch:30999 Loss:0.2643\n",
            "Epoch:31999 Loss:0.2637\n",
            "Epoch:32999 Loss:0.2631\n",
            "Epoch:33999 Loss:0.2625\n",
            "Epoch:34999 Loss:0.2620\n",
            "Epoch:35999 Loss:0.2614\n",
            "Epoch:36999 Loss:0.2609\n",
            "Epoch:37999 Loss:0.2604\n",
            "Epoch:38999 Loss:0.2599\n",
            "Epoch:39999 Loss:0.2594\n",
            "Epoch:40999 Loss:0.2589\n",
            "Epoch:41999 Loss:0.2585\n",
            "Epoch:42999 Loss:0.2580\n",
            "Epoch:43999 Loss:0.2576\n",
            "Epoch:44999 Loss:0.2571\n",
            "Epoch:45999 Loss:0.2567\n",
            "Epoch:46999 Loss:0.2563\n",
            "Epoch:47999 Loss:0.2558\n",
            "Epoch:48999 Loss:0.2554\n",
            "Epoch:49999 Loss:0.2550\n",
            "Epoch:50999 Loss:0.2546\n",
            "Epoch:51999 Loss:0.2543\n",
            "Epoch:52999 Loss:0.2539\n",
            "Epoch:53999 Loss:0.2535\n",
            "Epoch:54999 Loss:0.2531\n",
            "Epoch:55999 Loss:0.2528\n",
            "Epoch:56999 Loss:0.2524\n",
            "Epoch:57999 Loss:0.2521\n",
            "Epoch:58999 Loss:0.2517\n",
            "Epoch:59999 Loss:0.2514\n",
            "Epoch:60999 Loss:0.2511\n",
            "Epoch:61999 Loss:0.2507\n",
            "Epoch:62999 Loss:0.2504\n",
            "Epoch:63999 Loss:0.2501\n",
            "Epoch:64999 Loss:0.2498\n",
            "Epoch:65999 Loss:0.2495\n",
            "Epoch:66999 Loss:0.2492\n",
            "Epoch:67999 Loss:0.2489\n",
            "Epoch:68999 Loss:0.2486\n",
            "Epoch:69999 Loss:0.2483\n",
            "Epoch:70999 Loss:0.2480\n",
            "Epoch:71999 Loss:0.2477\n",
            "Epoch:72999 Loss:0.2475\n",
            "Epoch:73999 Loss:0.2472\n",
            "Epoch:74999 Loss:0.2469\n",
            "Epoch:75999 Loss:0.2467\n",
            "Epoch:76999 Loss:0.2464\n",
            "Epoch:77999 Loss:0.2462\n",
            "Epoch:78999 Loss:0.2459\n",
            "Epoch:79999 Loss:0.2457\n",
            "Epoch:80999 Loss:0.2454\n",
            "Epoch:81999 Loss:0.2452\n",
            "Epoch:82999 Loss:0.2450\n",
            "Epoch:83999 Loss:0.2447\n",
            "Epoch:84999 Loss:0.2445\n",
            "Epoch:85999 Loss:0.2443\n",
            "Epoch:86999 Loss:0.2441\n",
            "Epoch:87999 Loss:0.2438\n",
            "Epoch:88999 Loss:0.2436\n",
            "Epoch:89999 Loss:0.2434\n",
            "Epoch:90999 Loss:0.2432\n",
            "Epoch:91999 Loss:0.2430\n",
            "Epoch:92999 Loss:0.2428\n",
            "Epoch:93999 Loss:0.2426\n",
            "Epoch:94999 Loss:0.2424\n",
            "Epoch:95999 Loss:0.2422\n",
            "Epoch:96999 Loss:0.2420\n",
            "Epoch:97999 Loss:0.2418\n",
            "Epoch:98999 Loss:0.2416\n",
            "Epoch:99999 Loss:0.2415\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7yoIwl6_Wp9",
        "outputId": "baec0379-f1a2-402f-a05d-ff2d1dbf7f62"
      },
      "source": [
        "Vw"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.4477],\n",
              "        [ 2.1511],\n",
              "        [-0.5821]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTkB985n_a-N"
      },
      "source": [
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LogisticRegression, self).__init__()\n",
        "   \n",
        "  def forward(self, x, w):\n",
        "    y_pred = torch.sigmoid(x.mm(w))\n",
        "    return y_pred\n",
        "  \n",
        "  def backward(self):\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIX61-HEARe1"
      },
      "source": [
        "model = LogisticRegression()\n",
        "Vw = torch.rand(in_features, out_features, requires_grad=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOgQ3jveAexY"
      },
      "source": [
        "for epoch in range(epoch_n*1000):\n",
        "  y_pred = model(Vx, Vw)\n",
        "  loss = (-1.0*(\n",
        "              Vy*torch.log10(y_pred) + (1.0-Vy) * torch.log10(1.0-y_pred)\n",
        "          )).mean()\n",
        "  if (epoch + 1)%1000 == 0:\n",
        "    print('Epoch:{} Loss:{:.4f}'.format(epoch, loss))\n",
        "\n",
        "  loss.backward()\n",
        "  \n",
        "  Vw.data -= learning_rate * Vw.grad.data\n",
        "\n",
        "  Vw.grad.data.zero_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7vfBOcqAlBw"
      },
      "source": [
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LogisticRegression, self).__init__()\n",
        "    self.linear = nn.Linear(in_features, out_features, False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    y_pred = torch.sigmoid(self.linear(x))\n",
        "    return y_pred\n",
        "  \n",
        "  def backward(self):\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDU4t1n0BtN7",
        "outputId": "e116615d-32e1-4e51-b355-82f59fc78a03"
      },
      "source": [
        "model = LogisticRegression()\n",
        "loss_fn = nn.BCELoss()\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression(\n",
            "  (linear): Linear(in_features=3, out_features=1, bias=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkUagm3qCBIU",
        "outputId": "ab832885-8872-4d46-b3f6-196e8c20fbfd"
      },
      "source": [
        "for epoch in range(epoch_n*1000):\n",
        "  y_pred = model(Vx)\n",
        "  loss = loss_fn(y_pred, Vy)\n",
        "  if (epoch + 1)%1000 == 0:\n",
        "    print('Epoch:{} Loss:{:.4f}'.format(epoch, loss))\n",
        "\n",
        "  model.zero_grad()\n",
        "  loss.backward()\n",
        "\n",
        "  for parameter in model.parameters():\n",
        "    parameter.data -= learning_rate * parameter.grad.data\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:999 Loss:0.7016\n",
            "Epoch:1999 Loss:0.6944\n",
            "Epoch:2999 Loss:0.6876\n",
            "Epoch:3999 Loss:0.6812\n",
            "Epoch:4999 Loss:0.6752\n",
            "Epoch:5999 Loss:0.6695\n",
            "Epoch:6999 Loss:0.6640\n",
            "Epoch:7999 Loss:0.6588\n",
            "Epoch:8999 Loss:0.6538\n",
            "Epoch:9999 Loss:0.6491\n",
            "Epoch:10999 Loss:0.6445\n",
            "Epoch:11999 Loss:0.6402\n",
            "Epoch:12999 Loss:0.6360\n",
            "Epoch:13999 Loss:0.6320\n",
            "Epoch:14999 Loss:0.6281\n",
            "Epoch:15999 Loss:0.6245\n",
            "Epoch:16999 Loss:0.6209\n",
            "Epoch:17999 Loss:0.6176\n",
            "Epoch:18999 Loss:0.6143\n",
            "Epoch:19999 Loss:0.6112\n",
            "Epoch:20999 Loss:0.6082\n",
            "Epoch:21999 Loss:0.6054\n",
            "Epoch:22999 Loss:0.6026\n",
            "Epoch:23999 Loss:0.6000\n",
            "Epoch:24999 Loss:0.5974\n",
            "Epoch:25999 Loss:0.5950\n",
            "Epoch:26999 Loss:0.5926\n",
            "Epoch:27999 Loss:0.5904\n",
            "Epoch:28999 Loss:0.5882\n",
            "Epoch:29999 Loss:0.5861\n",
            "Epoch:30999 Loss:0.5841\n",
            "Epoch:31999 Loss:0.5822\n",
            "Epoch:32999 Loss:0.5803\n",
            "Epoch:33999 Loss:0.5785\n",
            "Epoch:34999 Loss:0.5768\n",
            "Epoch:35999 Loss:0.5751\n",
            "Epoch:36999 Loss:0.5735\n",
            "Epoch:37999 Loss:0.5720\n",
            "Epoch:38999 Loss:0.5705\n",
            "Epoch:39999 Loss:0.5690\n",
            "Epoch:40999 Loss:0.5676\n",
            "Epoch:41999 Loss:0.5663\n",
            "Epoch:42999 Loss:0.5650\n",
            "Epoch:43999 Loss:0.5638\n",
            "Epoch:44999 Loss:0.5626\n",
            "Epoch:45999 Loss:0.5614\n",
            "Epoch:46999 Loss:0.5603\n",
            "Epoch:47999 Loss:0.5592\n",
            "Epoch:48999 Loss:0.5582\n",
            "Epoch:49999 Loss:0.5571\n",
            "Epoch:50999 Loss:0.5562\n",
            "Epoch:51999 Loss:0.5552\n",
            "Epoch:52999 Loss:0.5543\n",
            "Epoch:53999 Loss:0.5534\n",
            "Epoch:54999 Loss:0.5526\n",
            "Epoch:55999 Loss:0.5517\n",
            "Epoch:56999 Loss:0.5509\n",
            "Epoch:57999 Loss:0.5501\n",
            "Epoch:58999 Loss:0.5494\n",
            "Epoch:59999 Loss:0.5487\n",
            "Epoch:60999 Loss:0.5480\n",
            "Epoch:61999 Loss:0.5473\n",
            "Epoch:62999 Loss:0.5466\n",
            "Epoch:63999 Loss:0.5460\n",
            "Epoch:64999 Loss:0.5453\n",
            "Epoch:65999 Loss:0.5447\n",
            "Epoch:66999 Loss:0.5441\n",
            "Epoch:67999 Loss:0.5436\n",
            "Epoch:68999 Loss:0.5430\n",
            "Epoch:69999 Loss:0.5425\n",
            "Epoch:70999 Loss:0.5420\n",
            "Epoch:71999 Loss:0.5415\n",
            "Epoch:72999 Loss:0.5410\n",
            "Epoch:73999 Loss:0.5405\n",
            "Epoch:74999 Loss:0.5401\n",
            "Epoch:75999 Loss:0.5396\n",
            "Epoch:76999 Loss:0.5392\n",
            "Epoch:77999 Loss:0.5387\n",
            "Epoch:78999 Loss:0.5383\n",
            "Epoch:79999 Loss:0.5379\n",
            "Epoch:80999 Loss:0.5376\n",
            "Epoch:81999 Loss:0.5372\n",
            "Epoch:82999 Loss:0.5368\n",
            "Epoch:83999 Loss:0.5365\n",
            "Epoch:84999 Loss:0.5361\n",
            "Epoch:85999 Loss:0.5358\n",
            "Epoch:86999 Loss:0.5355\n",
            "Epoch:87999 Loss:0.5351\n",
            "Epoch:88999 Loss:0.5348\n",
            "Epoch:89999 Loss:0.5345\n",
            "Epoch:90999 Loss:0.5342\n",
            "Epoch:91999 Loss:0.5339\n",
            "Epoch:92999 Loss:0.5337\n",
            "Epoch:93999 Loss:0.5334\n",
            "Epoch:94999 Loss:0.5331\n",
            "Epoch:95999 Loss:0.5329\n",
            "Epoch:96999 Loss:0.5326\n",
            "Epoch:97999 Loss:0.5324\n",
            "Epoch:98999 Loss:0.5322\n",
            "Epoch:99999 Loss:0.5319\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVd1YVSoCuz0",
        "outputId": "1011eb19-d99f-402e-ba7c-02682d1c409d"
      },
      "source": [
        "for parameter in model.parameters():\n",
        "  print(parameter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.7446,  3.0738, -1.0143]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EC5oSriUCzCq"
      },
      "source": [
        "model = LogisticRegression()\n",
        "optimizer = opt.SGD(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czAPfOaWDIDB",
        "outputId": "d6097834-59a8-4275-8524-494e2fa0add2"
      },
      "source": [
        "for epoch in range(epoch_n*1000):\n",
        "  y_pred = model(Vx)\n",
        "  loss = loss_fn(y_pred, Vy)\n",
        "  if (epoch + 1)%1000 == 0:\n",
        "    print('Epoch:{} Loss:{:.4f}'.format(epoch, loss))\n",
        "\n",
        "  model.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:999 Loss:0.7886\n",
            "Epoch:1999 Loss:0.7455\n",
            "Epoch:2999 Loss:0.7146\n",
            "Epoch:3999 Loss:0.6924\n",
            "Epoch:4999 Loss:0.6760\n",
            "Epoch:5999 Loss:0.6637\n",
            "Epoch:6999 Loss:0.6542\n",
            "Epoch:7999 Loss:0.6465\n",
            "Epoch:8999 Loss:0.6401\n",
            "Epoch:9999 Loss:0.6346\n",
            "Epoch:10999 Loss:0.6298\n",
            "Epoch:11999 Loss:0.6254\n",
            "Epoch:12999 Loss:0.6215\n",
            "Epoch:13999 Loss:0.6178\n",
            "Epoch:14999 Loss:0.6144\n",
            "Epoch:15999 Loss:0.6111\n",
            "Epoch:16999 Loss:0.6081\n",
            "Epoch:17999 Loss:0.6051\n",
            "Epoch:18999 Loss:0.6024\n",
            "Epoch:19999 Loss:0.5997\n",
            "Epoch:20999 Loss:0.5971\n",
            "Epoch:21999 Loss:0.5947\n",
            "Epoch:22999 Loss:0.5924\n",
            "Epoch:23999 Loss:0.5901\n",
            "Epoch:24999 Loss:0.5879\n",
            "Epoch:25999 Loss:0.5858\n",
            "Epoch:26999 Loss:0.5838\n",
            "Epoch:27999 Loss:0.5819\n",
            "Epoch:28999 Loss:0.5801\n",
            "Epoch:29999 Loss:0.5783\n",
            "Epoch:30999 Loss:0.5766\n",
            "Epoch:31999 Loss:0.5749\n",
            "Epoch:32999 Loss:0.5733\n",
            "Epoch:33999 Loss:0.5718\n",
            "Epoch:34999 Loss:0.5703\n",
            "Epoch:35999 Loss:0.5688\n",
            "Epoch:36999 Loss:0.5675\n",
            "Epoch:37999 Loss:0.5661\n",
            "Epoch:38999 Loss:0.5648\n",
            "Epoch:39999 Loss:0.5636\n",
            "Epoch:40999 Loss:0.5624\n",
            "Epoch:41999 Loss:0.5612\n",
            "Epoch:42999 Loss:0.5601\n",
            "Epoch:43999 Loss:0.5590\n",
            "Epoch:44999 Loss:0.5580\n",
            "Epoch:45999 Loss:0.5570\n",
            "Epoch:46999 Loss:0.5560\n",
            "Epoch:47999 Loss:0.5551\n",
            "Epoch:48999 Loss:0.5542\n",
            "Epoch:49999 Loss:0.5533\n",
            "Epoch:50999 Loss:0.5524\n",
            "Epoch:51999 Loss:0.5516\n",
            "Epoch:52999 Loss:0.5508\n",
            "Epoch:53999 Loss:0.5500\n",
            "Epoch:54999 Loss:0.5493\n",
            "Epoch:55999 Loss:0.5485\n",
            "Epoch:56999 Loss:0.5478\n",
            "Epoch:57999 Loss:0.5472\n",
            "Epoch:58999 Loss:0.5465\n",
            "Epoch:59999 Loss:0.5459\n",
            "Epoch:60999 Loss:0.5452\n",
            "Epoch:61999 Loss:0.5446\n",
            "Epoch:62999 Loss:0.5441\n",
            "Epoch:63999 Loss:0.5435\n",
            "Epoch:64999 Loss:0.5429\n",
            "Epoch:65999 Loss:0.5424\n",
            "Epoch:66999 Loss:0.5419\n",
            "Epoch:67999 Loss:0.5414\n",
            "Epoch:68999 Loss:0.5409\n",
            "Epoch:69999 Loss:0.5404\n",
            "Epoch:70999 Loss:0.5400\n",
            "Epoch:71999 Loss:0.5395\n",
            "Epoch:72999 Loss:0.5391\n",
            "Epoch:73999 Loss:0.5387\n",
            "Epoch:74999 Loss:0.5383\n",
            "Epoch:75999 Loss:0.5379\n",
            "Epoch:76999 Loss:0.5375\n",
            "Epoch:77999 Loss:0.5371\n",
            "Epoch:78999 Loss:0.5368\n",
            "Epoch:79999 Loss:0.5364\n",
            "Epoch:80999 Loss:0.5361\n",
            "Epoch:81999 Loss:0.5357\n",
            "Epoch:82999 Loss:0.5354\n",
            "Epoch:83999 Loss:0.5351\n",
            "Epoch:84999 Loss:0.5348\n",
            "Epoch:85999 Loss:0.5345\n",
            "Epoch:86999 Loss:0.5342\n",
            "Epoch:87999 Loss:0.5339\n",
            "Epoch:88999 Loss:0.5336\n",
            "Epoch:89999 Loss:0.5334\n",
            "Epoch:90999 Loss:0.5331\n",
            "Epoch:91999 Loss:0.5328\n",
            "Epoch:92999 Loss:0.5326\n",
            "Epoch:93999 Loss:0.5324\n",
            "Epoch:94999 Loss:0.5321\n",
            "Epoch:95999 Loss:0.5319\n",
            "Epoch:96999 Loss:0.5317\n",
            "Epoch:97999 Loss:0.5315\n",
            "Epoch:98999 Loss:0.5312\n",
            "Epoch:99999 Loss:0.5310\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l41IXLhRDURv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e270bf3-1328-4320-fc6b-e7335619e8f5"
      },
      "source": [
        "for parameter in model.parameters():\n",
        "  print(parameter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.7565,  3.1265, -1.0439]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbP0E_eEDYOl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}