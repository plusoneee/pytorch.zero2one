{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02 Convolutional Neural Network (CNN).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "430VgDRvhpk4"
      },
      "source": [
        "# Convolutional Neural Network (CNN)\n",
        "\n",
        "<img src=\"https://i.imgur.com/H8yBJsy.jpg\" alt=\"drawing\" width=\"800px\"/>\n",
        "\n",
        "* Import\n",
        "* Set The Device\n",
        "* Dataset - MNIST\n",
        "* Model: CNN\n",
        "* Loss Function & Optimizer\n",
        "* Training Model\n",
        "* Testing Model\n",
        "* Save & Load Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuOyZpEML_sW"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0uQd-UDKjjS"
      },
      "source": [
        "import torch\n",
        "\n",
        "# for Dataset\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# for Training Model\n",
        "import torch.nn as nn\n",
        "import torch.optim as opt"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NijRizrYLfUS"
      },
      "source": [
        "## Set The Device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "ySTJitT3MM_x",
        "outputId": "c1b90b88-4ec4-4dd6-ec4c-1860629dc0a2"
      },
      "source": [
        "torch.cuda.get_device_name()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1R7iQnbLj4t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ecbe55b-4782-45a0-e73d-876f01cec401"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDV2Hf4VMVgY"
      },
      "source": [
        "## Dataset - MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFG9kELTMFtN"
      },
      "source": [
        "train_dataset = MNIST(root = './data', train=True, download=True, transform=transforms.ToTensor())\n",
        "test_dataset= MNIST(root = './data', train=False, download=False, transform=transforms.ToTensor())"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMF2mW9LMeWB"
      },
      "source": [
        "## DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppj5B2FkMgrE"
      },
      "source": [
        "# hyperparameter \n",
        "train_batch_size = 64\n",
        "test_batch_szie = 64\n",
        "\n",
        "# train dataloader\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset, \n",
        "    batch_size=train_batch_size, \n",
        "    shuffle=True\n",
        "    )\n",
        "\n",
        "# test dataloader\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset, \n",
        "    batch_size=test_batch_szie, \n",
        "    shuffle=False\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ncr-tiIyNBrt"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwDgSQ_oMwMj"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(stride=2, kernel_size=2)\n",
        "        )\n",
        "        self.dense = nn.Sequential(\n",
        "            nn.Linear(in_features=14*14*128, out_features=1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.conv_layers(x) # \n",
        "        output = output.view(-1, 14*14*128)\n",
        "        output = self.dense(output)\n",
        "        return output"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgbmzNmYOvGH",
        "outputId": "287329e0-b383-4724-94a7-d4a1f9c479f7"
      },
      "source": [
        "model = CNN()\n",
        "model.to(device)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv_layers): Sequential(\n",
              "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (dense): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=1024, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=1024, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9QV_2z7PXS9"
      },
      "source": [
        "## Loss Function & Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIWtj7U-O1jg"
      },
      "source": [
        "# hypyerperameter\n",
        "learning_rate = 0.0001\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = opt.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j35SOep9Pl_D"
      },
      "source": [
        "## Training Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1NIaZ3GPjtb",
        "outputId": "d5034c36-d095-4dee-cc94-53b68c705055"
      },
      "source": [
        "# hyperparameter \n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for idx, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = loss_func(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (idx+1)%100 == 0:\n",
        "            print(\"Epoch: %d, Batch: %d, Loss: %.4f\" %(epoch+1, idx+1, loss.data))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Batch: 100, Loss: 0.4460\n",
            "Epoch: 1, Batch: 200, Loss: 0.2841\n",
            "Epoch: 1, Batch: 300, Loss: 0.0730\n",
            "Epoch: 1, Batch: 400, Loss: 0.1334\n",
            "Epoch: 1, Batch: 500, Loss: 0.1958\n",
            "Epoch: 1, Batch: 600, Loss: 0.0555\n",
            "Epoch: 1, Batch: 700, Loss: 0.0945\n",
            "Epoch: 1, Batch: 800, Loss: 0.1423\n",
            "Epoch: 1, Batch: 900, Loss: 0.0608\n",
            "Epoch: 2, Batch: 100, Loss: 0.0468\n",
            "Epoch: 2, Batch: 200, Loss: 0.0529\n",
            "Epoch: 2, Batch: 300, Loss: 0.0268\n",
            "Epoch: 2, Batch: 400, Loss: 0.0610\n",
            "Epoch: 2, Batch: 500, Loss: 0.0084\n",
            "Epoch: 2, Batch: 600, Loss: 0.0562\n",
            "Epoch: 2, Batch: 700, Loss: 0.0137\n",
            "Epoch: 2, Batch: 800, Loss: 0.0108\n",
            "Epoch: 2, Batch: 900, Loss: 0.0232\n",
            "Epoch: 3, Batch: 100, Loss: 0.0093\n",
            "Epoch: 3, Batch: 200, Loss: 0.0053\n",
            "Epoch: 3, Batch: 300, Loss: 0.0551\n",
            "Epoch: 3, Batch: 400, Loss: 0.0632\n",
            "Epoch: 3, Batch: 500, Loss: 0.0424\n",
            "Epoch: 3, Batch: 600, Loss: 0.0069\n",
            "Epoch: 3, Batch: 700, Loss: 0.0502\n",
            "Epoch: 3, Batch: 800, Loss: 0.0325\n",
            "Epoch: 3, Batch: 900, Loss: 0.0327\n",
            "Epoch: 4, Batch: 100, Loss: 0.0173\n",
            "Epoch: 4, Batch: 200, Loss: 0.0055\n",
            "Epoch: 4, Batch: 300, Loss: 0.0077\n",
            "Epoch: 4, Batch: 400, Loss: 0.0120\n",
            "Epoch: 4, Batch: 500, Loss: 0.0046\n",
            "Epoch: 4, Batch: 600, Loss: 0.0174\n",
            "Epoch: 4, Batch: 700, Loss: 0.0082\n",
            "Epoch: 4, Batch: 800, Loss: 0.0012\n",
            "Epoch: 4, Batch: 900, Loss: 0.0166\n",
            "Epoch: 5, Batch: 100, Loss: 0.0224\n",
            "Epoch: 5, Batch: 200, Loss: 0.0201\n",
            "Epoch: 5, Batch: 300, Loss: 0.0050\n",
            "Epoch: 5, Batch: 400, Loss: 0.0439\n",
            "Epoch: 5, Batch: 500, Loss: 0.0131\n",
            "Epoch: 5, Batch: 600, Loss: 0.0023\n",
            "Epoch: 5, Batch: 700, Loss: 0.0083\n",
            "Epoch: 5, Batch: 800, Loss: 0.0107\n",
            "Epoch: 5, Batch: 900, Loss: 0.0029\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ViDxE0gQjYW"
      },
      "source": [
        "## Testing Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBsfT1aDP4GX",
        "outputId": "0f51c109-449b-4176-abe2-79c067417d6f"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "for images, labels in test_loader:\n",
        "  images = images.to(device)\n",
        "  outputs = model(images)\n",
        "\n",
        "  _, pred = torch.max(outputs.data, 1)\n",
        "  \n",
        "  correct += (pred == labels.to(device)).sum()\n",
        "  total += labels.size(0)\n",
        "\n",
        "print('Accuracy:%.3f%%' %(100.0 * float(correct)/float(total)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:98.680%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWXwI0qbRMDM"
      },
      "source": [
        "## Save & Load Model\n",
        "\n",
        "* Method 1: save model's weight\n",
        "* Method 2: save entire model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9O8CfOcQsqv",
        "outputId": "796ecf4a-509f-48ec-f29d-931727af42d4"
      },
      "source": [
        "# method 1: save model weight\n",
        "torch.save(model.state_dict(), 'model.pkl')\n",
        "\n",
        "# load weight\n",
        "model = CNN()\n",
        "model.load_state_dict(torch.load('model.pkl'))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n12WsXkFo9Ah"
      },
      "source": [
        "torch.save(model, 'model3.pkl')"
      ],
      "execution_count": 27,
      "outputs": []
    }
  ]
}