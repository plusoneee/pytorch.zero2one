{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10_linear_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd1gfh36iGeW"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDovD3Q4iQHd"
      },
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jHtxmBwicLZ",
        "outputId": "f101aab0-9a94-45bd-ccb8-35bac782e9d8"
      },
      "source": [
        "# Add a transform that creates a tensor from the PIL image by adding transform:\n",
        "transform = transforms.Compose([\n",
        "    # you can add other transformations in this list\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# download CIFAR-10 dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "# Create Dataloader\n",
        "trainLoader = torch.utils.data.DataLoader(trainset, batch_size=8, shuffle=True, num_workers=2)\n",
        "testLoader = torch.utils.data.DataLoader(testset, batch_size=8, shuffle=False, num_workers=2)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pplDg_oGi0m1"
      },
      "source": [
        "# model \n",
        "class SimpleNet(nn.Module):\n",
        "  def __init__(self, input_size, num_class):\n",
        "    super(SimpleNet, self).__init__()\n",
        "    self.input = nn.Linear(input_size, 32)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.hidden_layer = nn.Linear(32, num_class)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    out = self.input(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.hidden_layer(out)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8yfsIKsmfoL",
        "outputId": "953e2861-cc47-4729-8983-7a9d4d71b545"
      },
      "source": [
        "# Parameters\n",
        "classes = trainset.classes\n",
        "class_num = len(classes)\n",
        "input_size = 32*32*3\n",
        "\n",
        "net = SimpleNet(input_size=input_size, num_class=class_num).to(device)\n",
        "print(net)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SimpleNet(\n",
            "  (input): Linear(in_features=3072, out_features=32, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (hidden_layer): Linear(in_features=32, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1FKXhXv0HMu"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 0.001\n",
        "epochs = 3\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmVsIbZmnJwf",
        "outputId": "91993596-88d6-4e7f-df48-dd24e8f4c958"
      },
      "source": [
        "# Train\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    for times, (images, labels) in enumerate(trainLoader):\n",
        "        # images are 64 (batch_size) *  32*32*3 tensor.\n",
        "        images = Variable(images.view(-1, 32*32*3)) # -1 means 8 here\n",
        "        labels = Variable(labels)\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (times+1) % 500 == 0:\n",
        "            print('Epoch: {}, Batch: {}, Loss: {}'.format(epoch+1, times+1, loss.data))\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Batch: 500, Loss: 1.7056517601013184\n",
            "Epoch: 1, Batch: 1000, Loss: 2.19059419631958\n",
            "Epoch: 1, Batch: 1500, Loss: 1.2345741987228394\n",
            "Epoch: 1, Batch: 2000, Loss: 1.6936646699905396\n",
            "Epoch: 1, Batch: 2500, Loss: 2.197434425354004\n",
            "Epoch: 1, Batch: 3000, Loss: 1.9401494264602661\n",
            "Epoch: 1, Batch: 3500, Loss: 1.563801884651184\n",
            "Epoch: 1, Batch: 4000, Loss: 2.572697639465332\n",
            "Epoch: 1, Batch: 4500, Loss: 1.5126606225967407\n",
            "Epoch: 1, Batch: 5000, Loss: 1.3178306818008423\n",
            "Epoch: 1, Batch: 5500, Loss: 1.880400538444519\n",
            "Epoch: 1, Batch: 6000, Loss: 1.5783478021621704\n",
            "Epoch: 2, Batch: 500, Loss: 1.8320305347442627\n",
            "Epoch: 2, Batch: 1000, Loss: 1.4147154092788696\n",
            "Epoch: 2, Batch: 1500, Loss: 0.982157289981842\n",
            "Epoch: 2, Batch: 2000, Loss: 1.2556840181350708\n",
            "Epoch: 2, Batch: 2500, Loss: 1.1594175100326538\n",
            "Epoch: 2, Batch: 3000, Loss: 1.5146551132202148\n",
            "Epoch: 2, Batch: 3500, Loss: 1.5738147497177124\n",
            "Epoch: 2, Batch: 4000, Loss: 1.5828971862792969\n",
            "Epoch: 2, Batch: 4500, Loss: 1.729058861732483\n",
            "Epoch: 2, Batch: 5000, Loss: 1.3640780448913574\n",
            "Epoch: 2, Batch: 5500, Loss: 1.5277677774429321\n",
            "Epoch: 2, Batch: 6000, Loss: 2.2066383361816406\n",
            "Epoch: 3, Batch: 500, Loss: 1.7903743982315063\n",
            "Epoch: 3, Batch: 1000, Loss: 1.5444416999816895\n",
            "Epoch: 3, Batch: 1500, Loss: 2.1918835639953613\n",
            "Epoch: 3, Batch: 2000, Loss: 1.421799659729004\n",
            "Epoch: 3, Batch: 2500, Loss: 2.203982353210449\n",
            "Epoch: 3, Batch: 3000, Loss: 1.4380916357040405\n",
            "Epoch: 3, Batch: 3500, Loss: 1.8623607158660889\n",
            "Epoch: 3, Batch: 4000, Loss: 1.9575304985046387\n",
            "Epoch: 3, Batch: 4500, Loss: 1.4889127016067505\n",
            "Epoch: 3, Batch: 5000, Loss: 1.06790030002594\n",
            "Epoch: 3, Batch: 5500, Loss: 1.8538639545440674\n",
            "Epoch: 3, Batch: 6000, Loss: 1.5849497318267822\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GE1w02bn6A3",
        "outputId": "d92db241-8ec6-4117-ae55-e98669995397"
      },
      "source": [
        "# calculate accuracy\n",
        "correct_num = 0\n",
        "total_num = 0\n",
        "\n",
        "for images, labels in testLoader:\n",
        "    images = Variable(images.view(-1, 32*32*3))\n",
        "    labels = Variable(labels)\n",
        "\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    \n",
        "    # output is 100x10 matrix;\n",
        "    output = net(images)\n",
        "    \n",
        "    # 1 means max by column;\n",
        "    # _ is -> value; predicted -> label(index).\n",
        "    _, predicted = torch.max(output.data, 1) \n",
        "    \n",
        "    total_num += labels.size(0) # len;\n",
        "    correct_num += (predicted == labels).sum()\n",
        "    \n",
        "print('accuracy: {} %'.format(float(correct_num)/ float(total_num) * 100))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 46.82 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}